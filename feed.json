{
	"version": "https://jsonfeed.org/version/1",
	"title": "Bugs and Bunnies -- Jay Lyerly",
	"icon": "https://micro.blog/jaylyerly/avatar.jpg",
	"home_page_url": "https://www.bugsandbunnies.org/",
	"feed_url": "https://www.bugsandbunnies.org/feed.json",
	"items": [
		
			{
				"id": "http://jaylyerly.micro.blog/2023/10/13/because-the-good.html",
				
				"content_html": "<p>Because the good hay is on the bottom.  Apparently.  #RabbitsOfMastodon</p>\n\n<p><img style=\"display:block; margin-left:auto; margin-right:auto;\" src=\"https://www.bugsandbunnies.org/uploads/2023/img-2800.jpeg\" alt=\"A German Lop rabbit completely covered in hay as she digs for the best piece at the bottom of the pile.\" title=\"The best piece.\" border=\"0\" width=\"600\" height=\"497\" /></p>\n",
				"content_text": "Because the good hay is on the bottom.  Apparently.  #RabbitsOfMastodon\n\n<img style=\"display:block; margin-left:auto; margin-right:auto;\" src=\"https://www.bugsandbunnies.org/uploads/2023/img-2800.jpeg\" alt=\"A German Lop rabbit completely covered in hay as she digs for the best piece at the bottom of the pile.\" title=\"The best piece.\" border=\"0\" width=\"600\" height=\"497\" />\n",
				"date_published": "2023-10-13T15:36:36-04:00",
				"url": "https://www.bugsandbunnies.org/2023/10/13/because-the-good.html"
			},
			{
				"id": "http://jaylyerly.micro.blog/2023/09/20/i-have-a.html",
				
				"content_html": "<p>I have a project that failed to build under Xcode 15. It links a 3rd party framework written in C++ but the link step fails with unresolved symbols. This <em>classic mode</em> flag for the linker fixed it right up.</p>\n\n<p><a href=\"https://mastodon.social/@jamesthomson/111098206089191122\">mastodon.social/@jamestho&hellip;</a></p>\n",
				"content_text": "I have a project that failed to build under Xcode 15. It links a 3rd party framework written in C++ but the link step fails with unresolved symbols. This _classic mode_ flag for the linker fixed it right up. \n\n[mastodon.social/@jamestho...](https://mastodon.social/@jamesthomson/111098206089191122)\n",
				"date_published": "2023-09-20T11:49:38-04:00",
				"url": "https://www.bugsandbunnies.org/2023/09/20/i-have-a.html"
			},
			{
				"id": "http://jaylyerly.micro.blog/2023/09/08/just-working-on.html",
				
				"content_html": "<p>Just working on some recreational Ansible.  As you do.</p>\n",
				"content_text": "Just working on some recreational Ansible.  As you do.\n",
				"date_published": "2023-09-08T12:58:58-04:00",
				"url": "https://www.bugsandbunnies.org/2023/09/08/just-working-on.html"
			},
			{
				"id": "http://jaylyerly.micro.blog/2023/08/23/wait-star-trek.html",
				
				"content_html": "<p>Wait, Star Trek: Strange New Worlds s2e10 is the end of the season?</p>\n\n<p>Oh no.</p>\n",
				"content_text": "Wait, Star Trek: Strange New Worlds s2e10 is the end of the season?\n\nOh no.\n",
				"date_published": "2023-08-23T17:45:01-04:00",
				"url": "https://www.bugsandbunnies.org/2023/08/23/wait-star-trek.html"
			},
			{
				"id": "http://jaylyerly.micro.blog/2023/08/23/python-in-excel.html",
				
				"content_html": "<p>Python in Excel!  But you have to write your python in the little Excel formula box?  Like getting a Ferrari but having to drive it with an app on your phone.</p>\n\n<p><a href=\"https://techcommunity.microsoft.com/t5/excel-blog/announcing-python-in-excel-combining-the-power-of-python-and-the/ba-p/3893439\">techcommunity.microsoft.com/t5/excel-&hellip;</a></p>\n",
				"content_text": "Python in Excel!  But you have to write your python in the little Excel formula box?  Like getting a Ferrari but having to drive it with an app on your phone.\n\n[techcommunity.microsoft.com/t5/excel-...](https://techcommunity.microsoft.com/t5/excel-blog/announcing-python-in-excel-combining-the-power-of-python-and-the/ba-p/3893439)\n",
				"date_published": "2023-08-23T09:01:38-04:00",
				"url": "https://www.bugsandbunnies.org/2023/08/23/python-in-excel.html"
			},
			{
				"id": "http://jaylyerly.micro.blog/2023/08/20/itd-be-cool.html",
				
				"content_html": "<p>It&rsquo;d be cool if the Apple Card (like the physical card) worked with Find My, so my wallet doesn&rsquo;t have to have a dog tag.</p>\n",
				"content_text": "It'd be cool if the Apple Card (like the physical card) worked with Find My, so my wallet doesn't have to have a dog tag.\n",
				"date_published": "2023-08-20T15:51:37-04:00",
				"url": "https://www.bugsandbunnies.org/2023/08/20/itd-be-cool.html"
			},
			{
				"id": "http://jaylyerly.micro.blog/2023/08/15/that-thing-where.html",
				
				"content_html": "<p>That thing where the list of states on a web form is alphabetized by state name, but display text is the two letter abbreviation&hellip; so the list goes NV, NE, NH, NJ, NM, NY, NC, ND.  Who looks at that and is like, yeah, we got it!</p>\n",
				"content_text": "That thing where the list of states on a web form is alphabetized by state name, but display text is the two letter abbreviation... so the list goes NV, NE, NH, NJ, NM, NY, NC, ND.  Who looks at that and is like, yeah, we got it!\n",
				"date_published": "2023-08-15T11:11:42-04:00",
				"url": "https://www.bugsandbunnies.org/2023/08/15/that-thing-where.html"
			},
			{
				"id": "http://jaylyerly.micro.blog/2023/08/10/am-i-reading.html",
				
				"content_html": "<p>Am I reading this right?</p>\n\n<p><a href=\"https://techcrunch.com/2023/08/10/disney-announces-another-price-hike-says-ad-supported-tier-is-coming-to-more-countries\">techcrunch.com/2023/08/1&hellip;</a></p>\n\n<p>Disney+ and Hulu are getting big price increases, $3 a month for both services on the ad-free tier.  So if you subscribe to both, it currently costs $26 and that&rsquo;s getting bumped to $32.  <strong>BUT</strong> they&rsquo;re adding a bundle of ad-free Hulu and Disney+ for $20.  So if you subscribe to both (like me!), this is actually going to save $6?</p>\n",
				"content_text": "Am I reading this right?\n\n[techcrunch.com/2023/08/1...](https://techcrunch.com/2023/08/10/disney-announces-another-price-hike-says-ad-supported-tier-is-coming-to-more-countries)\n\nDisney+ and Hulu are getting big price increases, $3 a month for both services on the ad-free tier.  So if you subscribe to both, it currently costs $26 and that's getting bumped to $32.  __BUT__ they're adding a bundle of ad-free Hulu and Disney+ for $20.  So if you subscribe to both (like me!), this is actually going to save $6?\n",
				"date_published": "2023-08-10T15:14:04-04:00",
				"url": "https://www.bugsandbunnies.org/2023/08/10/am-i-reading.html"
			},
			{
				"id": "http://jaylyerly.micro.blog/2023/08/01/office.html",
				"title": "Office 365",
				"content_html": "<p>I&rsquo;ve been moving SonicBunny Software from Google Workspace to Office 365 over the last few weeks. I like 365 and it offers a lot of features, but the time it takes to make a change is a bit of a shock. Configuring Exchange and so many things take 5 or 10 minutes to kick in. I guess Google is similar, but with a small installation, it seems like Google was nearly instant where O365 really does take several minutes. But I just hit the kicker &ndash; &lsquo;Please allow <strong>24 to 48 hours</strong> for this to take effect.&rsquo; Yowza!</p>\n",
				"content_text": "I've been moving SonicBunny Software from Google Workspace to Office 365 over the last few weeks. I like 365 and it offers a lot of features, but the time it takes to make a change is a bit of a shock. Configuring Exchange and so many things take 5 or 10 minutes to kick in. I guess Google is similar, but with a small installation, it seems like Google was nearly instant where O365 really does take several minutes. But I just hit the kicker -- 'Please allow __24 to 48 hours__ for this to take effect.' Yowza!\n",
				"date_published": "2023-08-01T14:24:09-04:00",
				"url": "https://www.bugsandbunnies.org/2023/08/01/office.html"
			},
			{
				"id": "http://jaylyerly.micro.blog/2023/07/13/first-hard-drive.html",
				
				"content_html": "<p>First hard drive, 10s of megabytes. Latest hard drive, 10s of terabytes. My brain can&rsquo;t really fathom how much more that is.</p>\n",
				"content_text": "First hard drive, 10s of megabytes. Latest hard drive, 10s of terabytes. My brain can't really fathom how much more that is.\n",
				"date_published": "2023-07-13T15:53:13-04:00",
				"url": "https://www.bugsandbunnies.org/2023/07/13/first-hard-drive.html"
			},
			{
				"id": "http://jaylyerly.micro.blog/2023/07/10/a-side-dish.html",
				
				"content_html": "<p>A side dish of &ldquo;cucumber salad&rdquo; is fine, but order a &ldquo;bowl of pickles&rdquo; and people look at you funny.</p>\n",
				"content_text": "A side dish of \"cucumber salad\" is fine, but order a \"bowl of pickles\" and people look at you funny.\n",
				"date_published": "2023-07-10T11:49:29-04:00",
				"url": "https://www.bugsandbunnies.org/2023/07/10/a-side-dish.html"
			},
			{
				"id": "http://jaylyerly.micro.blog/2023/07/05/hvac-died-today.html",
				
				"content_html": "<p>HVAC died today on (almost) the hottest day of the year, 8 days after it’s annual service. Luckily, the AC peeps were out in about an hour! Turned out to be a loose wire in an electrical box — easy fix.  🥵</p>\n\n<p><a href=\"https://www.allamerican-nc.com\">www.allamerican-nc.com</a></p>\n",
				"content_text": "HVAC died today on (almost) the hottest day of the year, 8 days after it’s annual service. Luckily, the AC peeps were out in about an hour! Turned out to be a loose wire in an electrical box — easy fix.  🥵\n\n[www.allamerican-nc.com](https://www.allamerican-nc.com)\n",
				"date_published": "2023-07-05T19:41:25-04:00",
				"url": "https://www.bugsandbunnies.org/2023/07/05/hvac-died-today.html"
			},
			{
				"id": "http://jaylyerly.micro.blog/2023/07/03/iphone-rerouted-us.html",
				
				"content_html": "<p>iPhone rerouted us over the weekend to avoid “severe weather”. First time I’ve seen that. It helped but we still nearly floated away.</p>\n",
				"content_text": "iPhone rerouted us over the weekend to avoid “severe weather”. First time I’ve seen that. It helped but we still nearly floated away. \n",
				"date_published": "2023-07-03T14:24:54-04:00",
				"url": "https://www.bugsandbunnies.org/2023/07/03/iphone-rerouted-us.html"
			},
			{
				"id": "http://jaylyerly.micro.blog/2023/06/28/can-you-guess.html",
				"title": "Can you guess the TV show from a random person in the opening credits?",
				"content_html": "<p>Only scored 9 out of 10. It&rsquo;s the black and white western that got me.</p>\n\n<p><a href=\"https://www.metv.com/quiz/can-you-guess-the-tv-show-from-a-random-person-in-the-opening-credits\">Can you guess the TV show from a random person in the opening credits?</a>:</p>\n\n<blockquote>Prove you recognize these total strangers from TV.</blockquote>\n",
				"content_text": "Only scored 9 out of 10. It's the black and white western that got me. \n\n<p><a href=\"https://www.metv.com/quiz/can-you-guess-the-tv-show-from-a-random-person-in-the-opening-credits\">Can you guess the TV show from a random person in the opening credits?</a>:</p>\n\n<blockquote>Prove you recognize these total strangers from TV.</blockquote>\n",
				"date_published": "2023-06-28T10:55:36-04:00",
				"url": "https://www.bugsandbunnies.org/2023/06/28/can-you-guess.html"
			},
			{
				"id": "http://jaylyerly.micro.blog/2023/06/27/weve-been-using.html",
				
				"content_html": "<p>We&rsquo;ve been using UniFi Talk for a while for our home phone. It&rsquo;s kinda&hellip; basic. But they got SMS support a while ago! Yay! But the SMS to email relay has a delay of usually 10 minutes.  Boo!  Not great when the repair guy texts that he&rsquo;s 10 minutes out and you get the text 10 minutes later. <strong>But</strong>, turns out you can also be notified via Slack webhook, which happens immediately. Now we get instant delivery of SMS messages to our home number and only have to go through like three different systems. Yay?</p>\n",
				"content_text": "We've been using UniFi Talk for a while for our home phone. It's kinda... basic. But they got SMS support a while ago! Yay! But the SMS to email relay has a delay of usually 10 minutes.  Boo!  Not great when the repair guy texts that he's 10 minutes out and you get the text 10 minutes later. **But**, turns out you can also be notified via Slack webhook, which happens immediately. Now we get instant delivery of SMS messages to our home number and only have to go through like three different systems. Yay?\n",
				"date_published": "2023-06-27T11:53:20-04:00",
				"url": "https://www.bugsandbunnies.org/2023/06/27/weve-been-using.html"
			},
			{
				"id": "http://jaylyerly.micro.blog/2023/06/25/furniture-was-rearranged.html",
				
				"content_html": "<p>Furniture was rearranged without authorization. Dragon is not amused! #RabbitsOfMastodon</p>\n\n<p><img src=\"uploads/2023/image.jpg\" width=\"600\" height=\"565\" alt=\"\"></p>\n",
				"content_text": "Furniture was rearranged without authorization. Dragon is not amused! #RabbitsOfMastodon\n\n<img src=\"uploads/2023/image.jpg\" width=\"600\" height=\"565\" alt=\"\">\n",
				"date_published": "2023-06-25T19:33:24-04:00",
				"url": "https://www.bugsandbunnies.org/2023/06/25/furniture-was-rearranged.html"
			},
			{
				"id": "http://jaylyerly.micro.blog/2023/06/15/callisto-jupyter-and.html",
				"title": "Callisto, Jupyter and Mac Optimized Machine Learning -- Part 2",
				"content_html": "<p>In my last post, I looked at how to install TensorFlow optimized for Apple Silicon.  This time around, I&rsquo;ll explore Apple Silicon support in <a href=\"https://pytorch.org\">PyTorch</a>, another wildly popular library for machine learning.</p>\n\n<p>Setting up <a href=\"https://www.callistoapp.com\">Callisto</a> for PyTorch is easy!  The suggested <code>pip</code> command is</p>\n\n<pre><code>pip install torch torchvision torchaudio\n</code></pre>\n\n<p>And we can do that directly in the <a href=\"https://www.callistoapp.com\">Callisto</a> package manager.  Remember, you can install multiple packages at a time by adding a space separated list, so paste <code>torch torchvision torchaudio</code> into the install field and away we go!</p>\n\n<p>I was looking for little example to run and compare performance of PyTorch on the Apple Silicon CPU with performance on the GPU.  To be quite honest, it was difficult to find a straightforward example.  Fortunately, I ran across <a href=\"https://github.com/mrdbourke/pytorch-apple-silicon/blob/main/01_cifar10_tinyvgg.ipynb\">this notebook</a> by Daniel Bourke.  Daniel works through an example training a model on both the CPU device and the MPS device. MPS is the Metal Performance Shaders backend which uses Apple&rsquo;s Metal framework to harness the power of the M1&rsquo;s graphics hardware.  In this example, he creates a Convolutional Neural Network (CNN) for image classification and compares the performance of the CPU and MPS backends.</p>\n\n<p>The bottom line?  MPS is at least 10x faster than using the CPU.  In Daniel&rsquo;s posted notebook, he saw a speed up of around 10.6.  On my machine, I saw a performance increase of about 11.1x.  The best thing about optimization in PyTorch is that it doesn&rsquo;t require any extra work.  For Mac, the MPS backend is the default so everyone benefits from the performance boost.</p>\n\n<p>In addition to TensorFlow and PyTorch, I checked some other popular Python ML libraries and to see how they took advantage of Apple Silicon.  While some libraries have choosen not to pursue Apple Silicon specific optimization, all of them run correctly in CPU mode.</p>\n\n<ul>\n<li><a href=\"https://keras.io\">Keras</a>\n\n<ul>\n<li><a href=\"https://keras.io/about/\">Built on TensorFlow</a>, Keras should show significant performance improvements when you use an optimized version of TensorFlow</li>\n</ul></li>\n<li><a href=\"https://docs.fast.ai\">FastAI</a>\n\n<ul>\n<li><a href=\"https://docs.fast.ai/#about-fastai\">Built on PyTorch</a>, fastai should show significant performance improvements when you use an optimized version of PyTorch</li>\n</ul></li>\n<li><a href=\"https://scikit-learn.org\">Scikit-learn</a>\n\n<ul>\n<li>To avoid the management overhead and complexity, <a href=\"https://scikit-learn.org/stable/faq.html#will-you-add-gpu-support\">scikit-learn doesn&rsquo;t support GPU acceleration</a></li>\n</ul></li>\n<li><a href=\"https://numpy.org\">Numpy</a>\n\n<ul>\n<li>It maybe be possible to improve performance in numpy by compiling it against an optimized BLAS library which uses Apple&rsquo;s Accelerate framework.  The Accelerate framework provides high performance, vector optimized mathematical functions which are tuned for Apple Silicon.  This is a bit involved and will require more research to see what impact this can have.</li>\n</ul></li>\n<li><a href=\"https://xgboost.readthedocs.io\">XGBoost</a>\n\n<ul>\n<li>XGBoost seems to be focused on GPUs that support CUDA for hardware acceleration and <a href=\"https://github.com/dmlc/xgboost/issues/6408#issuecomment-1056543760\">currently have no plans to support Apple Silicon.</a></li>\n</ul></li>\n<li><a href=\"https://numba.pydata.org\">Numba</a>\n\n<ul>\n<li>Numba also seems to focus only on <a href=\"https://numba.readthedocs.io/en/stable/user/5minguide.html#gpu-targets\">CUDA based GPU acceleration</a></li>\n</ul></li>\n</ul>\n",
				"content_text": "In my last post, I looked at how to install TensorFlow optimized for Apple Silicon.  This time around, I'll explore Apple Silicon support in [PyTorch](https://pytorch.org), another wildly popular library for machine learning.\n\nSetting up [Callisto](https://www.callistoapp.com) for PyTorch is easy!  The suggested `pip` command is \n\n```\npip install torch torchvision torchaudio\n```\n\nAnd we can do that directly in the [Callisto](https://www.callistoapp.com) package manager.  Remember, you can install multiple packages at a time by adding a space separated list, so paste `torch torchvision torchaudio` into the install field and away we go!  \n\nI was looking for little example to run and compare performance of PyTorch on the Apple Silicon CPU with performance on the GPU.  To be quite honest, it was difficult to find a straightforward example.  Fortunately, I ran across [this notebook](https://github.com/mrdbourke/pytorch-apple-silicon/blob/main/01_cifar10_tinyvgg.ipynb) by Daniel Bourke.  Daniel works through an example training a model on both the CPU device and the MPS device. MPS is the Metal Performance Shaders backend which uses Apple's Metal framework to harness the power of the M1's graphics hardware.  In this example, he creates a Convolutional Neural Network (CNN) for image classification and compares the performance of the CPU and MPS backends.\n\nThe bottom line?  MPS is at least 10x faster than using the CPU.  In Daniel's posted notebook, he saw a speed up of around 10.6.  On my machine, I saw a performance increase of about 11.1x.  The best thing about optimization in PyTorch is that it doesn't require any extra work.  For Mac, the MPS backend is the default so everyone benefits from the performance boost.\n\nIn addition to TensorFlow and PyTorch, I checked some other popular Python ML libraries and to see how they took advantage of Apple Silicon.  While some libraries have choosen not to pursue Apple Silicon specific optimization, all of them run correctly in CPU mode.\n\n   * [Keras](https://keras.io)\n      * [Built on TensorFlow](https://keras.io/about/), Keras should show significant performance improvements when you use an optimized version of TensorFlow\n   * [FastAI](https://docs.fast.ai)\n      * [Built on PyTorch](https://docs.fast.ai/#about-fastai), fastai should show significant performance improvements when you use an optimized version of PyTorch\n   * [Scikit-learn](https://scikit-learn.org)\n      * To avoid the management overhead and complexity, [scikit-learn doesn't support GPU acceleration](https://scikit-learn.org/stable/faq.html#will-you-add-gpu-support\n)\n   * [Numpy](https://numpy.org)\n      * It maybe be possible to improve performance in numpy by compiling it against an optimized BLAS library which uses Apple's Accelerate framework.  The Accelerate framework provides high performance, vector optimized mathematical functions which are tuned for Apple Silicon.  This is a bit involved and will require more research to see what impact this can have.\n   * [XGBoost](https://xgboost.readthedocs.io)\n      * XGBoost seems to be focused on GPUs that support CUDA for hardware acceleration and [currently have no plans to support Apple Silicon.](https://github.com/dmlc/xgboost/issues/6408#issuecomment-1056543760)\n   * [Numba](https://numba.pydata.org)\n      * Numba also seems to focus only on [CUDA based GPU acceleration](https://numba.readthedocs.io/en/stable/user/5minguide.html#gpu-targets\n)\n\n",
				"date_published": "2023-06-15T15:50:21-04:00",
				"url": "https://www.bugsandbunnies.org/2023/06/15/callisto-jupyter-and.html",
				"tags": ["Callisto"]
			},
			{
				"id": "http://jaylyerly.micro.blog/2023/06/12/callisto-jupyter-and.html",
				"title": "Callisto, Jupyter and Mac Optimized Machine Learning ",
				"content_html": "<p>We build <a href=\"https://www.callistoapp.com\">Callisto</a> with the mindset that <a href=\"https://www.callistoapp.com\">Callisto</a> is the best way to do data science on a Mac.  A part of that is to helping users get the most out of their Mac hardware by using computational libraries optimized for Apple Silicon chips.  <a href=\"https://www.tensorflow.org\">TensorFlow</a> is a very popular library for machine learning, so let&rsquo;s take a look and see what it takes to use an M1 optimized version of TensorFlow with a Jupyter notebook in Callisto.</p>\n\n<p>TensorFlow has a feature called <a href=\"https://blog.tensorflow.org/2021/06/pluggabledevice-device-plugins-for-TensorFlow.html\">PluggableDevice</a> which let&rsquo;s developers create plugins for different pieces of ML hardware.  Conveniently for us, Apple has written a <a href=\"https://developer.apple.com/metal/tensorflow-plugin/\">plugin for Metal</a> which is <em>heavily</em> optimized for Apple Silicon devices like the M1 and M2 chips.  Now we just have to get it installed.</p>\n\n<p>You <em>should</em> be able to just install the TensorFlow library for the Mac and then the PluggableDevice for Metal, which you&rsquo;d do with these commands:</p>\n\n<pre><code>pip install tensorflow-macos\npip install tensorflow-metal\n</code></pre>\n\n<p>With Callisto, you can use our fancy package manager interface and install <code>tensorflow-macos</code> and <code>tensorflow-metal</code>.  Unfortunately, other package dependencies mean that pip won&rsquo;t install the latest <code>tensorflow-macos</code>, version 2.12.0, but instead, fails back one version to 2.11.0.  On the other hand, pip will install the latest version of <code>tensorflow-metal</code> but the PluggableDevice interface is a C API and is tightly bound to the version.  While these modules installed, at runtime there&rsquo;s a symbol mismatch error and the Metal plugin fails to load.</p>\n\n<p>Cue montage of trying to install several permutations of these two packages.</p>\n\n<p>To jump to the end, as suggested in this <a href=\"https://developer.apple.com/forums/thread/722361\">post</a> on the Apple Dev Forum, more recent versions seem to have issues and falling back to <code>tensorflow-macos</code> version 2.9.0 and <code>tensor flow-metal</code> version 0.5.0 does work with no issues.  Pip will install those versions with the following commands:</p>\n\n<pre><code>pip install tensorflow-macos==2.9.0\npip install tensorflow-metal==0.5.0\n</code></pre>\n\n<p>Don&rsquo;t forget, you can specify versions using Callisto&rsquo;s package manager right in the package field by adding the version specifier.  Instead of just <code>tensorflow-macos</code>, use <code>tensorflow-macos==2.9.0</code>.</p>\n\n<p>Now we&rsquo;re up and running, let&rsquo;s do some tests!  We want to compare just running on the CPU versus running with the hardware accelerated Metal GPU.  Here&rsquo;s a little bit of code to disable the GPU accelerated device in TensorFlow:</p>\n\n<pre><code class=\"language-python\">import tensorflow as tf\ntf.__version__\n\ndisable_gpu = True\n\nif disable_gpu:\n    tf.config.set_visible_devices([], 'GPU')\n\ntf.config.get_visible_devices()\n\n</code></pre>\n\n<p>When <code>disable_gpu</code> is true, you should only see one CPU device in the output.  When not disabling the GPU, you should see both the CPU and GPU in the output.  TensorFlow doesn&rsquo;t deal well with changing the visibility after the library is up and running, so to switch the state of the GPU, remember to restart your Jupyter kernel.</p>\n\n<p>Now we&rsquo;re ready to test!  First I tried this <a href=\"https://www.tensorflow.org/tutorials/quickstart/beginner\">Quickstart for Beginners</a> from the TF website.  Running this example on the CPU, it completed in 7 seconds.  Enabling the GPU, it runs in 42 seconds.  What, what?!  It&rsquo;s slower using the fancy Metal optimized GPU driver?  Yep, turns out that&rsquo;s right.  As noted on Apple&rsquo;s <a href=\"https://developer.apple.com/metal/tensorflow-plugin/\">tensorflow-metal page</a>, the CPU can be faster for small jobs.  Well that&rsquo;s a little disappointing.</p>\n\n<p>Now if we look at Apple&rsquo;s example on that same page, it&rsquo;s got a little more heavy lifting to do.  Running that on my M1 CPU, it runs in just under a half an hour at 29 minutes and 12 seconds.  On the GPU, it blazes through the job in 5 minutes and 10 seconds!  Cutting my run time to <strong>1/6</strong> of the original is defintely a solid improvement.  That kind of performance spike makes all the installation headaches worth it!</p>\n\n<p>With <code>tensorflow-metal</code> on the cusp of a 1.0.0 release, we&rsquo;re excited to see how we can integrate this into our builds and include this out of the box with <a href=\"https://www.callistoapp.com\">Callisto</a>, but until then, these instructions should help shepherd you through a manual install.</p>\n",
				"content_text": "We build [Callisto](https://www.callistoapp.com) with the mindset that [Callisto](https://www.callistoapp.com) is the best way to do data science on a Mac.  A part of that is to helping users get the most out of their Mac hardware by using computational libraries optimized for Apple Silicon chips.  [TensorFlow](https://www.tensorflow.org) is a very popular library for machine learning, so let's take a look and see what it takes to use an M1 optimized version of TensorFlow with a Jupyter notebook in Callisto.\n\nTensorFlow has a feature called [PluggableDevice](https://blog.tensorflow.org/2021/06/pluggabledevice-device-plugins-for-TensorFlow.html) which let's developers create plugins for different pieces of ML hardware.  Conveniently for us, Apple has written a [plugin for Metal](https://developer.apple.com/metal/tensorflow-plugin/) which is _heavily_ optimized for Apple Silicon devices like the M1 and M2 chips.  Now we just have to get it installed.\n\nYou _should_ be able to just install the TensorFlow library for the Mac and then the PluggableDevice for Metal, which you'd do with these commands: \n\n```\npip install tensorflow-macos\npip install tensorflow-metal\n```\n\nWith Callisto, you can use our fancy package manager interface and install `tensorflow-macos` and `tensorflow-metal`.  Unfortunately, other package dependencies mean that pip won't install the latest `tensorflow-macos`, version 2.12.0, but instead, fails back one version to 2.11.0.  On the other hand, pip will install the latest version of `tensorflow-metal` but the PluggableDevice interface is a C API and is tightly bound to the version.  While these modules installed, at runtime there's a symbol mismatch error and the Metal plugin fails to load.\n\nCue montage of trying to install several permutations of these two packages.\n\nTo jump to the end, as suggested in this [post](https://developer.apple.com/forums/thread/722361) on the Apple Dev Forum, more recent versions seem to have issues and falling back to `tensorflow-macos` version 2.9.0 and `tensor flow-metal` version 0.5.0 does work with no issues.  Pip will install those versions with the following commands:\n\n```\npip install tensorflow-macos==2.9.0\npip install tensorflow-metal==0.5.0\n```\n\nDon't forget, you can specify versions using Callisto's package manager right in the package field by adding the version specifier.  Instead of just `tensorflow-macos`, use `tensorflow-macos==2.9.0`.  \n\nNow we're up and running, let's do some tests!  We want to compare just running on the CPU versus running with the hardware accelerated Metal GPU.  Here's a little bit of code to disable the GPU accelerated device in TensorFlow:\n\n```python\nimport tensorflow as tf\ntf.__version__\n\ndisable_gpu = True\n\nif disable_gpu:\n    tf.config.set_visible_devices([], 'GPU')\n\ntf.config.get_visible_devices()\n\n```\n\nWhen `disable_gpu` is true, you should only see one CPU device in the output.  When not disabling the GPU, you should see both the CPU and GPU in the output.  TensorFlow doesn't deal well with changing the visibility after the library is up and running, so to switch the state of the GPU, remember to restart your Jupyter kernel.\n\nNow we're ready to test!  First I tried this [Quickstart for Beginners](https://www.tensorflow.org/tutorials/quickstart/beginner) from the TF website.  Running this example on the CPU, it completed in 7 seconds.  Enabling the GPU, it runs in 42 seconds.  What, what?!  It's slower using the fancy Metal optimized GPU driver?  Yep, turns out that's right.  As noted on Apple's [tensorflow-metal page](https://developer.apple.com/metal/tensorflow-plugin/), the CPU can be faster for small jobs.  Well that's a little disappointing. \n\nNow if we look at Apple's example on that same page, it's got a little more heavy lifting to do.  Running that on my M1 CPU, it runs in just under a half an hour at 29 minutes and 12 seconds.  On the GPU, it blazes through the job in 5 minutes and 10 seconds!  Cutting my run time to **1/6** of the original is defintely a solid improvement.  That kind of performance spike makes all the installation headaches worth it!\n\nWith `tensorflow-metal` on the cusp of a 1.0.0 release, we're excited to see how we can integrate this into our builds and include this out of the box with [Callisto](https://www.callistoapp.com), but until then, these instructions should help shepherd you through a manual install.\n \n",
				"date_published": "2023-06-12T16:16:54-04:00",
				"url": "https://www.bugsandbunnies.org/2023/06/12/callisto-jupyter-and.html",
				"tags": ["Callisto"]
			},
			{
				"id": "http://jaylyerly.micro.blog/2023/06/08/christian-and-others.html",
				
				"content_html": "<p>Christian (and others) got a raw deal a lot like the folks behind Tweetbot and Twitterific. As a small dev it&rsquo;s become a <em>huge</em> gamble to create an app based on an API that you do not own. They can (and clearly will) rip the rug out from under you.</p>\n\n<p><a href=\"https://mastodon.social/@christianselig/110509739563895220\">mastodon.social/@christia&hellip;</a></p>\n",
				"content_text": "Christian (and others) got a raw deal a lot like the folks behind Tweetbot and Twitterific. As a small dev it's become a _huge_ gamble to create an app based on an API that you do not own. They can (and clearly will) rip the rug out from under you. \n\n[mastodon.social/@christia...](https://mastodon.social/@christianselig/110509739563895220)\n",
				"date_published": "2023-06-08T15:22:54-04:00",
				"url": "https://www.bugsandbunnies.org/2023/06/08/christian-and-others.html"
			},
			{
				"id": "http://jaylyerly.micro.blog/2023/06/07/so-glad-to.html",
				
				"content_html": "<p>So glad to see the emphasis on testing in the Sync to iCloud with CKSyncEngine session!  More of this please.</p>\n\n<p>#WWDC</p>\n\n<p><a href=\"https://developer.apple.com/wwdc23/10188\">developer.apple.com/wwdc23/10&hellip;</a></p>\n",
				"content_text": "So glad to see the emphasis on testing in the Sync to iCloud with CKSyncEngine session!  More of this please.\n\n#WWDC\n\n[developer.apple.com/wwdc23/10...](https://developer.apple.com/wwdc23/10188)\n",
				"date_published": "2023-06-07T13:37:17-04:00",
				"url": "https://www.bugsandbunnies.org/2023/06/07/so-glad-to.html"
			},
			{
				"id": "http://jaylyerly.micro.blog/2023/06/06/wwdc-keynote-post.html",
				"title": "#WWDC 2023 -- Keynote Post Mortem",
				"content_html": "<p>Wow.  That was a lot.</p>\n\n<p>I was pleasantly surprised to see the Apple Silicon MacPro.  Some folks online expressed a bit of sticker shock, but it&rsquo;s a high end machine and comes with a high end price.  Part of that is due to the Mac Studio.  Before the release of the Studio, your desktop Mac choices were between a Mac mini and a Mac Pro.  In that line up, the mini had to stretch to the mid-range and the old Intel Mac Pro started off in the upper mid range.  Now the Studio is positioned to take up that &ldquo;medium&rdquo; position, where you&rsquo;re doing serious work, but not making Avatar A20: The Final Avataring.  With the Studio providing coverage for those mid-range workflows, the Pro is really only for top end jobs, especially those that require PCIe card interfaces like a fiber channel interface.</p>\n\n<p>Siri didn&rsquo;t get the big upgrade I was hoping for.  The whole ChatGPT thing has really exploded in the last few months and that&rsquo;s a little too soon for Apple to act on it in time for this year&rsquo;s OS release.  Siri is getting the ability to handle back-to-back requests.  We&rsquo;ll have to see how that plays out with the betas this summer.</p>\n\n<p>Looking forward to today&rsquo;s &ldquo;What&rsquo;s New in Xcode 15&rdquo; to get a better feel for the Xcode improvements. The State of the Union seemed to focus on a lot of support for visionOS, but that may just be the shock and awe talking after the big reveal yesterday.  Browsing through all the sessions, I&rsquo;ve book marked 35 I&rsquo;d like to see, which is a ton.  Hopefully I&rsquo;ll get through ten this week.</p>\n\n<p>Scanning through the session topics, I see a lot of Swift / SwiftUI talks and, as you might expect, a lot of visionOS sessions.  Sadly, a lot of topics I&rsquo;m interested in aren&rsquo;t getting a lot of attention.  tvOS has one session about the Continuity Camera support.  There are only a handful of sessions about iOS, iPhone, or iPad and most of those are about running your app in the visionOS environment.  HomeKit isn&rsquo;t mentioned at all.  CarPlay and HomePod get one session each.  The <em>reality</em> is that even at a week long, online developer conference, there&rsquo;s only so much bandwidth.  There&rsquo;s so much for Apple to tell us about visionOS and this is their one chance, so it&rsquo;s all magic googles, all the time.</p>\n\n<p>Now if they just handed out some free samples.</p>\n",
				"content_text": "Wow.  That was a lot.\n\nI was pleasantly surprised to see the Apple Silicon MacPro.  Some folks online expressed a bit of sticker shock, but it's a high end machine and comes with a high end price.  Part of that is due to the Mac Studio.  Before the release of the Studio, your desktop Mac choices were between a Mac mini and a Mac Pro.  In that line up, the mini had to stretch to the mid-range and the old Intel Mac Pro started off in the upper mid range.  Now the Studio is positioned to take up that \"medium\" position, where you're doing serious work, but not making Avatar A20: The Final Avataring.  With the Studio providing coverage for those mid-range workflows, the Pro is really only for top end jobs, especially those that require PCIe card interfaces like a fiber channel interface.\n\nSiri didn't get the big upgrade I was hoping for.  The whole ChatGPT thing has really exploded in the last few months and that's a little too soon for Apple to act on it in time for this year's OS release.  Siri is getting the ability to handle back-to-back requests.  We'll have to see how that plays out with the betas this summer.\n\nLooking forward to today's \"What's New in Xcode 15\" to get a better feel for the Xcode improvements. The State of the Union seemed to focus on a lot of support for visionOS, but that may just be the shock and awe talking after the big reveal yesterday.  Browsing through all the sessions, I've book marked 35 I'd like to see, which is a ton.  Hopefully I'll get through ten this week.\n\nScanning through the session topics, I see a lot of Swift / SwiftUI talks and, as you might expect, a lot of visionOS sessions.  Sadly, a lot of topics I'm interested in aren't getting a lot of attention.  tvOS has one session about the Continuity Camera support.  There are only a handful of sessions about iOS, iPhone, or iPad and most of those are about running your app in the visionOS environment.  HomeKit isn't mentioned at all.  CarPlay and HomePod get one session each.  The _reality_ is that even at a week long, online developer conference, there's only so much bandwidth.  There's so much for Apple to tell us about visionOS and this is their one chance, so it's all magic googles, all the time.\n\nNow if they just handed out some free samples.\n\n",
				"date_published": "2023-06-06T11:19:11-04:00",
				"url": "https://www.bugsandbunnies.org/2023/06/06/wwdc-keynote-post.html"
			},
			{
				"id": "http://jaylyerly.micro.blog/2023/05/31/turns-out-if.html",
				
				"content_html": "<p>Turns out if you register an Mac UUID on the Apple Dev Portal, but forget to set the platform to macOS, the portal decides that it is&hellip; an iPod.  So I&rsquo;ve got that going for me, which is nice.</p>\n",
				"content_text": "Turns out if you register an Mac UUID on the Apple Dev Portal, but forget to set the platform to macOS, the portal decides that it is... an iPod.  So I've got that going for me, which is nice.\n",
				"date_published": "2023-05-31T17:51:47-04:00",
				"url": "https://www.bugsandbunnies.org/2023/05/31/turns-out-if.html"
			},
			{
				"id": "http://jaylyerly.micro.blog/2023/05/30/california-dreamin.html",
				"title": "California Dreamin' -- WWDC 2023",
				"content_html": "\n\n<p>It&rsquo;s about a week before WWDC 2023 kicks off in sunny California, so here&rsquo;s a list of things I&rsquo;m hoping to see come out of Cupertino.  I&rsquo;m skipping the AR/VR stuff, since it&rsquo;s been speculated ad nauseam.  I&rsquo;m sure it&rsquo;ll be cool and awesome and weird and probably not cheap.  And maybe it&rsquo;ll make me dizzy</p>\n\n<blockquote>\n<p>TLDR; Better Xcode, Better Siri, Better Mac Catalyst</p>\n</blockquote>\n\n<h2 id=\"xcode\">Xcode</h2>\n\n<p>Mostly, I just want Xcode to be better.  Don&rsquo;t crash.  Don&rsquo;t be slow.  Is that too much to ask?</p>\n\n<h4 id=\"spm-handling\">SPM Handling</h4>\n\n<p>We&rsquo;ve all seen it.  Switch branches, hit build and be faced with</p>\n\n<blockquote>\n<p>Build operations are disabled: Package loading in progress. Please try again later.</p>\n</blockquote>\n\n<p>I spend a lot of time working on <a href=\"https://www.callistoapp.com\">Callisto</a>, which is kind of a big app.  We have dependencies split out into frameworks and it can take SPM <em>a while</em> to resolve all the packages when switching branches.  So I hit this quite a lot.  Usually, Xcode does a great job of queueing up actions when it&rsquo;s busy.  Like if you do a clean build and then run unit tests, it will finish the clean and then do the testing.  That&rsquo;s all I want for SPM resolution.</p>\n\n<h4 id=\"better-swiftui-tooling\">Better SwiftUI Tooling</h4>\n\n<p>I haven&rsquo;t written a lot of SwiftUI.  We toyed with it early on building <a href=\"https://www.callistoapp.com\">Callisto</a>, but it wasn&rsquo;t ready for a big project like that.  A couple months ago, we thought about trying to build a screen here or there with SwiftUI, but ran into roadblocks.  One of the key features of SwiftUI is the <em>live preview</em>.  To make those work, Xcode compiles bits of your code behind the scenes and shows them in preview pane.  <a href=\"https://www.callistoapp.com\">Callisto</a> is a Catalyst app but has an AppKit plugin for doing Mac system things.  Xcode could not handle that when trying to make a SwiftUI preview.  Xcode would try to compile the AppKit code with UIKit and become very upset when it didn&rsquo;t work.  That left our foray into SwiftUI dead in the water.</p>\n\n<h4 id=\"siri-for-xcode\">Siri for Xcode</h4>\n\n<p>I&rsquo;ve dabbled a bit with ChatGPT as a coding assistant.  It&rsquo;s great for small tasks with fiddly parameters.  For instance, I needed to get the timestamp of some files.  That&rsquo;s the kind of thing that&rsquo;s straightforward, but you don&rsquo;t do it often, so you have to look up the specific API to stat the file and which attributes correspond to the creation date / modification date, etc.  ChatGPT spit that code right out and I could move on to other things.  But there&rsquo;s friction there and the opportunity for a bespoke Xcode experience.  I&rsquo;m cautiously optimistic Apple will do something in this space, but I&rsquo;m afraid it won&rsquo;t be groundbreaking.  Because, you know&hellip; Siri.</p>\n\n<h2 id=\"catalyst-and-ios-updates\">Catalyst and iOS Updates</h2>\n\n<p>Since <a href=\"https://www.callistoapp.com\">Callisto</a> is built with Mac Catalyst, these are the sorts of updates we&rsquo;d love to see as developers.</p>\n\n<h4 id=\"dynamic-type-on-mac\">Dynamic Type on Mac</h4>\n\n<p>Dynamic Type on iOS has been around for 10+ years.  That&rsquo;s the bit in iOS Settings that lets you make the text on your device a little bigger or a lot bigger than standard.  All the apps that support Dynamic Type will pick up the change and text across the whole device changes size.  That&rsquo;s great!  A boon for aging eyes everywhere.</p>\n\n<p>But it isn&rsquo;t supported at all on macOS.  This <a href=\"https://www.apple.com/newsroom/2023/05/apple-previews-live-speech-personal-voice-and-more-new-accessibility-features/\">recent announcement</a> about new accessibility features coming in iOS 17 mentions</p>\n\n<blockquote>\n<p>For users with low vision, Text Size is now easier to adjust across Mac apps such as Finder, Messages, Mail, Calendar, and Notes.</p>\n</blockquote>\n\n<p>That sounds a lot like Dynamic Text on the Mac, so fingers crossed.</p>\n\n<h4 id=\"auxiliary-window-replacement\">Auxiliary Window Replacement</h4>\n\n<p>Back in the day, lots of Mac apps used auxiliary windows that served as things like inspectors and floating tool panels.  Apps like Photoshop had a bunch of these &ndash; paintbrushes, color panels, etc.  You can still see these in AppKit apps like Preview and Quicktime Player, where the inspector is an auxiliary window.  When you switch apps, it disappears to cut down on clutter.  Right now, there&rsquo;s nothing like that for Catalyst.  The UIScene API for managing windows doesn&rsquo;t have that level of distinction.  Hopefully, at WWDC we&rsquo;ll see a more mature Stage Manager implementation and at least some way of distinguishing main content windows and helper windows.</p>\n\n<h4 id=\"multiple-processes-on-ios\">Multiple Processes on iOS</h4>\n\n<p><a href=\"https://www.callistoapp.com\">Callisto</a> includes an embedded Python distribution for running the Jupyter Python Kernel.  On the Mac, we just spawn a separate process and run Python normally.  On iPad, we use a heavily modified Python to run in the same process space as the app to comply with App Store requirements.  In practice, that hamstrings <a href=\"https://www.callistoapp.com\">Callisto</a> on the iPad a great deal.  With a renewed interest in <a href=\"https://www.apple.com/newsroom/2023/05/apple-brings-final-cut-pro-and-logic-pro-to-ipad/\">Pro apps</a> on the iPad, it&rsquo;d be incredible if we were allowed to run multiple processes and level the playing field between an M1 iPad and an M1 MacBook.</p>\n\n<p>Yeah, never going to happen.</p>\n\n<h2 id=\"other-stuff\">Other Stuff</h2>\n\n<h4 id=\"passwords\">Passwords</h4>\n\n<p>A lot of folks have called for a dedicated Passwords app instead of burying password management in Settings.  I&rsquo;m all for that, but I&rsquo;d also love to see password sharing via your Apple Family.  That&rsquo;s really the last feature I&rsquo;d need to leave 1Password behind.  1Password has been fantastic, but they&rsquo;ve really pivoted to a corporate focus, so they&rsquo;re less of good fit when I just want to share the Netflix password with my family.  (Only for persons in my immediate family, residing in the same household.  Netflix, if you&rsquo;re reading this, I promise.)</p>\n\n<h4 id=\"hksv-streaming-api\">HKSV Streaming API</h4>\n\n<p>I&rsquo;m pretty heavily invested in the HomeKit ecosystem and I&rsquo;m mostly happy with it.  (I&rsquo;m looking at you Siri.)  I&rsquo;ve got several third party apps that will stream video from my cameras, but they can only show live feeds.  HKSV (HomeKit Secure Video) records events from these cameras and saves to iCloud, but scrolling back through time is only available via Apple&rsquo;s Home app.  Third party apps aren&rsquo;t able to access the history of clips because there&rsquo;s just no API for it.  With HomeKit (hopefully) maturing a little more this year, Apple should make that available to developers.</p>\n\n<h4 id=\"better-siri-for-mac\">Better Siri for Mac</h4>\n\n<p>Yes, macOS has Siri.  But as underwhelming as Siri is on iOS, it&rsquo;s worse on Mac.</p>\n\n<p>In my notes, I wrote down &ldquo;Not Brain Dead&rdquo;.  Siri just fails at the most basic things sometimes.  When I try to open an app in my Applications folder with the phrase &ldquo;Open AppName&rdquo;, it fails maybe 2 out of 3 times.  I&rsquo;m not sure why it&rsquo;s so bad and I don&rsquo;t know of any way to debug it.</p>\n\n<p>I usually use my laptop with the lid closed with external monitor, keyboard, webcam, etc.  That means I can&rsquo;t use &ldquo;Hey Siri&rdquo; for security reasons.  I agree being able to turn off an always-on microphone is important, but if Siri is a serious feature, why can&rsquo;t I explicitly grant permission for Siri to listen with an external microphone?  It is interesting to note that &ldquo;Hey Siri&rdquo; does work with the ($1600) Mac Studio Display.  That&rsquo;s attributed to the onboard A13 chip.</p>\n\n<p>Another bit of low hanging fruit for Siri is menu commands.  At least it seems low hanging to me.  If I&rsquo;m using an app like Xcode, that has a menu command called &lsquo;Build&rsquo;, I would expect Siri to understand if I said &ldquo;Hey Siri, Build&rdquo;.  But like the double meat burger, Siri is strictly off the menu.</p>\n\n<p>But the real dream is a conversational Siri.  We&rsquo;ve all seen Iron Man.  We&rsquo;ve seen Tony talking to Jarvis like a person as he works.  Could Siri ever do that in the context of Xcode?  Playing with ChatGPT has teased this kind of reality.  &ldquo;Write a method to delete all the files in a given directory.&rdquo;  That&rsquo;s a thing ChatGPT can do in a web browser window.  Why can&rsquo;t Siri to do that in Xcode?  Imagine an Apple trained <a href=\"https://en.wikipedia.org/wiki/Large_language_model\">LLM</a> that especially knew about Swift, UIKit, and all the Apple technologies.  Add in the context of the project you&rsquo;re currently working on.  Talk about a developer accelerant.  But that&rsquo;s a <em>big</em> leap, so it&rsquo;s doubtful we&rsquo;ll see that this year, but maybe the first step?</p>\n\n<h2 id=\"things-we-won-t-see-at-wwdc\">Things We Won&rsquo;t See at WWDC</h2>\n\n<h4 id=\"apple-silicon-mac-pro\">Apple Silicon Mac Pro</h4>\n\n<p>Apple announced Apple Silicon for Mac at WWDC of 2020, three years ago, and the first commercial M1 Macs shipped in November of 2020.  At the time, Apple <a href=\"https://www.apple.com/newsroom/2020/06/apple-announces-mac-transition-to-apple-silicon/\">estimated</a> that the transition to Apple Silicon would take about two years.  It&rsquo;s been two and a half years since that first M1 MacBook Air shipped but the Mac Pro still sports an Intel chip.  Something has clearly run amok.</p>\n\n<p>But the rumor mill is pretty quiet on the Mac Pro front.  Usually at this point, there would be at least some mention of the debut of a high profile, flagship Mac.  It seems like we&rsquo;ll be waiting until later in the year to see what kind of behemoth you can build out of lots of iPhone chips.</p>\n\n<h4 id=\"homepod-appletv\">HomePod + AppleTV</h4>\n\n<p>Years ago, HomePod ran its own fork of iOS called AudioOS.  Apple merged AudioOS with tvOS several revisions back so now both these home devices run tvOS.  Because they do similar things &ndash; played media and power HomeKit &ndash; that makes a lot of sense.  But the two devices remained separate at a hardware level &ndash; a smart speaker and a TV streamer.  I&rsquo;ve been waiting for the hybrid devices for <em>years</em> now.  There&rsquo;s the HomePod with a screen, like an Amazon Echo Show, that does HomePod things, but augmented with a display.  And there&rsquo;s the AppleTV with a mic and speaker.  The mic let&rsquo;s you talk to the TV without holding the button on the remote and the speaker acts as a center channel for multiple HomePod sound stage.</p>\n\n<p>Those are both consumer products, so not the kind of thing they&rsquo;d squeeze into the WWDC Keynote, especially with the AR/VR announcement, but maybe this fall, just in time for Christmas.</p>\n\n<p>Will we see any of this at WWDC?  I certainly hope so.  But there&rsquo;s only one way to find out.</p>\n\n<p>No sleep &lsquo;til DubDub!</p>\n",
				"content_text": "It's about a week before WWDC 2023 kicks off in sunny California, so here's a list of things I'm hoping to see come out of Cupertino.  I'm skipping the AR/VR stuff, since it's been speculated ad nauseam.  I'm sure it'll be cool and awesome and weird and probably not cheap.  And maybe it'll make me dizzy\n\n> TLDR; Better Xcode, Better Siri, Better Mac Catalyst\n\n## Xcode\n\nMostly, I just want Xcode to be better.  Don't crash.  Don't be slow.  Is that too much to ask?\n\n#### SPM Handling\n\nWe've all seen it.  Switch branches, hit build and be faced with\n\n> Build operations are disabled: Package loading in progress. Please try again later.\n\nI spend a lot of time working on [Callisto](https://www.callistoapp.com), which is kind of a big app.  We have dependencies split out into frameworks and it can take SPM _a while_ to resolve all the packages when switching branches.  So I hit this quite a lot.  Usually, Xcode does a great job of queueing up actions when it's busy.  Like if you do a clean build and then run unit tests, it will finish the clean and then do the testing.  That's all I want for SPM resolution.\n\n#### Better SwiftUI Tooling\n\nI haven't written a lot of SwiftUI.  We toyed with it early on building [Callisto](https://www.callistoapp.com), but it wasn't ready for a big project like that.  A couple months ago, we thought about trying to build a screen here or there with SwiftUI, but ran into roadblocks.  One of the key features of SwiftUI is the _live preview_.  To make those work, Xcode compiles bits of your code behind the scenes and shows them in preview pane.  [Callisto](https://www.callistoapp.com) is a Catalyst app but has an AppKit plugin for doing Mac system things.  Xcode could not handle that when trying to make a SwiftUI preview.  Xcode would try to compile the AppKit code with UIKit and become very upset when it didn't work.  That left our foray into SwiftUI dead in the water.\n\n#### Siri for Xcode\n\nI've dabbled a bit with ChatGPT as a coding assistant.  It's great for small tasks with fiddly parameters.  For instance, I needed to get the timestamp of some files.  That's the kind of thing that's straightforward, but you don't do it often, so you have to look up the specific API to stat the file and which attributes correspond to the creation date / modification date, etc.  ChatGPT spit that code right out and I could move on to other things.  But there's friction there and the opportunity for a bespoke Xcode experience.  I'm cautiously optimistic Apple will do something in this space, but I'm afraid it won't be groundbreaking.  Because, you know... Siri.\n\n## Catalyst and iOS Updates\n\nSince [Callisto](https://www.callistoapp.com) is built with Mac Catalyst, these are the sorts of updates we'd love to see as developers.\n\n#### Dynamic Type on Mac\n\nDynamic Type on iOS has been around for 10+ years.  That's the bit in iOS Settings that lets you make the text on your device a little bigger or a lot bigger than standard.  All the apps that support Dynamic Type will pick up the change and text across the whole device changes size.  That's great!  A boon for aging eyes everywhere. \n\nBut it isn't supported at all on macOS.  This [recent announcement](https://www.apple.com/newsroom/2023/05/apple-previews-live-speech-personal-voice-and-more-new-accessibility-features/) about new accessibility features coming in iOS 17 mentions \n\n> For users with low vision, Text Size is now easier to adjust across Mac apps such as Finder, Messages, Mail, Calendar, and Notes.\n\nThat sounds a lot like Dynamic Text on the Mac, so fingers crossed. \n\n#### Auxiliary Window Replacement\n\nBack in the day, lots of Mac apps used auxiliary windows that served as things like inspectors and floating tool panels.  Apps like Photoshop had a bunch of these -- paintbrushes, color panels, etc.  You can still see these in AppKit apps like Preview and Quicktime Player, where the inspector is an auxiliary window.  When you switch apps, it disappears to cut down on clutter.  Right now, there's nothing like that for Catalyst.  The UIScene API for managing windows doesn't have that level of distinction.  Hopefully, at WWDC we'll see a more mature Stage Manager implementation and at least some way of distinguishing main content windows and helper windows.\n\n#### Multiple Processes on iOS\n\n[Callisto](https://www.callistoapp.com) includes an embedded Python distribution for running the Jupyter Python Kernel.  On the Mac, we just spawn a separate process and run Python normally.  On iPad, we use a heavily modified Python to run in the same process space as the app to comply with App Store requirements.  In practice, that hamstrings [Callisto](https://www.callistoapp.com) on the iPad a great deal.  With a renewed interest in [Pro apps](https://www.apple.com/newsroom/2023/05/apple-brings-final-cut-pro-and-logic-pro-to-ipad/) on the iPad, it'd be incredible if we were allowed to run multiple processes and level the playing field between an M1 iPad and an M1 MacBook.  \n\nYeah, never going to happen.\n\n## Other Stuff\n\n#### Passwords\n\nA lot of folks have called for a dedicated Passwords app instead of burying password management in Settings.  I'm all for that, but I'd also love to see password sharing via your Apple Family.  That's really the last feature I'd need to leave 1Password behind.  1Password has been fantastic, but they've really pivoted to a corporate focus, so they're less of good fit when I just want to share the Netflix password with my family.  (Only for persons in my immediate family, residing in the same household.  Netflix, if you're reading this, I promise.)\n\n#### HKSV Streaming API\n\nI'm pretty heavily invested in the HomeKit ecosystem and I'm mostly happy with it.  (I'm looking at you Siri.)  I've got several third party apps that will stream video from my cameras, but they can only show live feeds.  HKSV (HomeKit Secure Video) records events from these cameras and saves to iCloud, but scrolling back through time is only available via Apple's Home app.  Third party apps aren't able to access the history of clips because there's just no API for it.  With HomeKit (hopefully) maturing a little more this year, Apple should make that available to developers.\n\n#### Better Siri for Mac\n\nYes, macOS has Siri.  But as underwhelming as Siri is on iOS, it's worse on Mac.\n\nIn my notes, I wrote down \"Not Brain Dead\".  Siri just fails at the most basic things sometimes.  When I try to open an app in my Applications folder with the phrase \"Open AppName\", it fails maybe 2 out of 3 times.  I'm not sure why it's so bad and I don't know of any way to debug it.\n\nI usually use my laptop with the lid closed with external monitor, keyboard, webcam, etc.  That means I can't use \"Hey Siri\" for security reasons.  I agree being able to turn off an always-on microphone is important, but if Siri is a serious feature, why can't I explicitly grant permission for Siri to listen with an external microphone?  It is interesting to note that \"Hey Siri\" does work with the ($1600) Mac Studio Display.  That's attributed to the onboard A13 chip.  \n\nAnother bit of low hanging fruit for Siri is menu commands.  At least it seems low hanging to me.  If I'm using an app like Xcode, that has a menu command called 'Build', I would expect Siri to understand if I said \"Hey Siri, Build\".  But like the double meat burger, Siri is strictly off the menu.\n\nBut the real dream is a conversational Siri.  We've all seen Iron Man.  We've seen Tony talking to Jarvis like a person as he works.  Could Siri ever do that in the context of Xcode?  Playing with ChatGPT has teased this kind of reality.  \"Write a method to delete all the files in a given directory.\"  That's a thing ChatGPT can do in a web browser window.  Why can't Siri to do that in Xcode?  Imagine an Apple trained [LLM](https://en.wikipedia.org/wiki/Large_language_model) that especially knew about Swift, UIKit, and all the Apple technologies.  Add in the context of the project you're currently working on.  Talk about a developer accelerant.  But that's a _big_ leap, so it's doubtful we'll see that this year, but maybe the first step?\n\n## Things We Won't See at WWDC\n\n#### Apple Silicon Mac Pro\n\nApple announced Apple Silicon for Mac at WWDC of 2020, three years ago, and the first commercial M1 Macs shipped in November of 2020.  At the time, Apple [estimated](https://www.apple.com/newsroom/2020/06/apple-announces-mac-transition-to-apple-silicon/) that the transition to Apple Silicon would take about two years.  It's been two and a half years since that first M1 MacBook Air shipped but the Mac Pro still sports an Intel chip.  Something has clearly run amok. \n\nBut the rumor mill is pretty quiet on the Mac Pro front.  Usually at this point, there would be at least some mention of the debut of a high profile, flagship Mac.  It seems like we'll be waiting until later in the year to see what kind of behemoth you can build out of lots of iPhone chips.\n\n#### HomePod + AppleTV\n\nYears ago, HomePod ran its own fork of iOS called AudioOS.  Apple merged AudioOS with tvOS several revisions back so now both these home devices run tvOS.  Because they do similar things -- played media and power HomeKit -- that makes a lot of sense.  But the two devices remained separate at a hardware level -- a smart speaker and a TV streamer.  I've been waiting for the hybrid devices for _years_ now.  There's the HomePod with a screen, like an Amazon Echo Show, that does HomePod things, but augmented with a display.  And there's the AppleTV with a mic and speaker.  The mic let's you talk to the TV without holding the button on the remote and the speaker acts as a center channel for multiple HomePod sound stage.  \n\nThose are both consumer products, so not the kind of thing they'd squeeze into the WWDC Keynote, especially with the AR/VR announcement, but maybe this fall, just in time for Christmas.\n\nWill we see any of this at WWDC?  I certainly hope so.  But there's only one way to find out.\n\nNo sleep 'til DubDub!\n",
				"date_published": "2023-05-30T15:59:05-04:00",
				"url": "https://www.bugsandbunnies.org/2023/05/30/california-dreamin.html",
				"tags": ["Swift","WWDC"]
			},
			{
				"id": "http://jaylyerly.micro.blog/2023/05/26/remember-two-door.html",
				
				"content_html": "<p>Remember two door cars?  Pepperidge Farm remembers.</p>\n",
				"content_text": "Remember two door cars?  Pepperidge Farm remembers. \n",
				"date_published": "2023-05-26T08:42:45-04:00",
				"url": "https://www.bugsandbunnies.org/2023/05/26/remember-two-door.html"
			},
			{
				"id": "http://jaylyerly.micro.blog/2023/05/25/got-some-spam.html",
				
				"content_html": "<p>Got some spam email today promising to use AI to increase my sales meetings by 10x!  Thank you AI, you know just what I want.  Coming soon &ndash; recreational root canals, weekend tax audits and more sauerkraut.</p>\n",
				"content_text": "Got some spam email today promising to use AI to increase my sales meetings by 10x!  Thank you AI, you know just what I want.  Coming soon -- recreational root canals, weekend tax audits and more sauerkraut.\n",
				"date_published": "2023-05-25T09:30:03-04:00",
				"url": "https://www.bugsandbunnies.org/2023/05/25/got-some-spam.html"
			},
			{
				"id": "http://jaylyerly.micro.blog/2023/05/23/pricing-schemes-for.html",
				
				"content_html": "<p>Pricing schemes for streaming services are weird. Most of them charge more for higher quality streams. So you get the same content, just an inferior version of it. It&rsquo;s the equivalent of going to the Louvre and being allowed closer to the Mona Lisa if you paid more.</p>\n\n<blockquote><em>\"There's something so human about taking something great, and ruining it a little so you can have more of it.\" -- Michael, The Good Place</em> </blockquote>\n",
				"content_text": "Pricing schemes for streaming services are weird. Most of them charge more for higher quality streams. So you get the same content, just an inferior version of it. It's the equivalent of going to the Louvre and being allowed closer to the Mona Lisa if you paid more.\n\n<blockquote><em>\"There's something so human about taking something great, and ruining it a little so you can have more of it.\" -- Michael, The Good Place</em> </blockquote>\n",
				"date_published": "2023-05-23T15:31:56-04:00",
				"url": "https://www.bugsandbunnies.org/2023/05/23/pricing-schemes-for.html"
			},
			{
				"id": "http://jaylyerly.micro.blog/2023/05/09/about-final-cut.html",
				
				"content_html": "<p>About Final Cut for iPad&hellip; so many MacRumors commenters are writing it off because it&rsquo;s a subscription - $5/mth or $50/yr. But Mac FCP is $300! So the part where Apple &ldquo;wins” on this is at 6 yeas. If FCP is so good that you&rsquo;re still using it in 6 years, then they totally deserve the money. It also means dabblers like me can pay $10 a year and do the two little hobby projects that come up where multi-cam would be handy. I can only imagine the fury if Apple had dropped a one-time $300 iPad app.</p>\n",
				"content_text": "About Final Cut for iPad... so many MacRumors commenters are writing it off because it's a subscription - $5/mth or $50/yr. But Mac FCP is $300! So the part where Apple \"wins” on this is at 6 yeas. If FCP is so good that you're still using it in 6 years, then they totally deserve the money. It also means dabblers like me can pay $10 a year and do the two little hobby projects that come up where multi-cam would be handy. I can only imagine the fury if Apple had dropped a one-time $300 iPad app.\n",
				"date_published": "2023-05-09T11:17:43-04:00",
				"url": "https://www.bugsandbunnies.org/2023/05/09/about-final-cut.html"
			},
			{
				"id": "http://jaylyerly.micro.blog/2023/04/24/better-app-launching.html",
				"title": "Better App Launching with SwiftUI for Unit Tests",
				"content_html": "<pre>\nTL;DR -- In SwiftUI, use a fake testing `App` instead of your real `App` \nto make sure you're actually testing your code. \n</pre>\n\n<p>For unit testing, test coverage is an important metric.  How much of your code base are you exercising during unit tests?  Xcode is, unfortunately, not too bright when it comes to measuring coverage.  It doesn&rsquo;t have the intelligence to know if you&rsquo;re &ldquo;testing&rdquo; a line of code, just that the line of code was executed.  This is a problem right off the bat.</p>\n\n<p>I&rsquo;ve got a new app project in Xcode.  The app does a little and I want to start adding tests before it gets too big.  So I add a unit test target and Xcode plops in some empty tests.  I run the unit tests, and they all pass since they&rsquo;re empty.  I check the coverage and it&rsquo;s at 36%!  How can that be, I didn&rsquo;t test <em>anything</em>?</p>\n\n<p>Xcode, the blissful idiot, is really reporting that 36% of the code was executed while running the unit tests.  Usually, when an app starts up, it does some bootstrapping.  You might set up your persistent storage, draw a couple of Views on screen, and maybe talk to the network.  Xcode counts all that as &ldquo;testing&rdquo; because it ran during a unit test.</p>\n\n<p>To make the test coverage more accurate, we need to do as little as possible outside of our actual unit tests.  Jon Reid <a href=\"https://qualitycoding.org/ios-app-delegate-testing/\">has a write-up</a> of how to do this with a UIKit app by swapping out the app delegate during tests.  But SwiftUI introduces a whole new startup sequence so we need a new approach for SwiftUI&rsquo;s new app lifecycle.</p>\n\n<p>After some futzing around, turns out it&rsquo;s easy!</p>\n\n<pre><code class=\"language-swift\">struct TestApp: App {\t\t\t\t\t// 1\n    var body: some Scene {\n        WindowGroup {\n            Text(&quot;I'm running tests!&quot;)\n        }\n    }\n}\n\n@main\t\t\t\t\t\t\t\t\t\t// 2\nstruct TestDriver {\n    static func main() {\n        if NSClassFromString(&quot;XCTestCase&quot;) != nil {    // 3\n            TestApp.main()\n        } else {\n            MyRealApp.main()\n        }\n    }\n}\n</code></pre>\n\n<p>There are three key points that make this work:</p>\n\n<ol>\n    <li>We need a dummy `App` struct to use instead of the real app.  This simple stand-in circumvents all your usual app startup machinery.  Instead of all the normal bootstrapping, we'll just get a window with the text \"I'm running tests!\".</li>\n<li>Remove the `@main` from your `App` implementation and add it here to `TestDriver`.  Swift uses `@main` to figure out how to start your app.  The `App` protocol provides a default implementation that, according to the docs, 'manages the launch process in a platform-appropriate way'.  But by inserting our own wrapper layer here around, we can control _which_ `main()` is called.</li>\n<li>That brings us to the final point, use the good old `NSClassFromString` to decide if the testing bundle has been injected into our process.  `XCTestCase` is only available during testing, so this is a reliable way to decide if unit testing is underway.  Based on that, we can call the `main` method of either our real app or our testing stand-in.  It turns out that the default implementation of `main` knows to use its parent struct to bootstrap the SwiftUI app.</li>\n</ol>\n\n<p>Now when I run unit tests, my coverage is at 0.8%!  That&rsquo;s more like it.  In order to boost my test coverage, I now have to actually test code.  And the code coverage metric really starts to mean something.</p>\n",
				"content_text": "<pre>\nTL;DR -- In SwiftUI, use a fake testing `App` instead of your real `App` \nto make sure you're actually testing your code. \n</pre>\n\nFor unit testing, test coverage is an important metric.  How much of your code base are you exercising during unit tests?  Xcode is, unfortunately, not too bright when it comes to measuring coverage.  It doesn't have the intelligence to know if you're \"testing\" a line of code, just that the line of code was executed.  This is a problem right off the bat.\n\nI've got a new app project in Xcode.  The app does a little and I want to start adding tests before it gets too big.  So I add a unit test target and Xcode plops in some empty tests.  I run the unit tests, and they all pass since they're empty.  I check the coverage and it's at 36%!  How can that be, I didn't test _anything_? \n\nXcode, the blissful idiot, is really reporting that 36% of the code was executed while running the unit tests.  Usually, when an app starts up, it does some bootstrapping.  You might set up your persistent storage, draw a couple of Views on screen, and maybe talk to the network.  Xcode counts all that as \"testing\" because it ran during a unit test. \n\nTo make the test coverage more accurate, we need to do as little as possible outside of our actual unit tests.  Jon Reid [has a write-up](https://qualitycoding.org/ios-app-delegate-testing/) of how to do this with a UIKit app by swapping out the app delegate during tests.  But SwiftUI introduces a whole new startup sequence so we need a new approach for SwiftUI's new app lifecycle.\n\nAfter some futzing around, turns out it's easy!\n\n```swift\nstruct TestApp: App {\t\t\t\t\t// 1\n    var body: some Scene {\n        WindowGroup {\n            Text(\"I'm running tests!\")\n        }\n    }\n}\n\n@main\t\t\t\t\t\t\t\t\t\t// 2\nstruct TestDriver {\n    static func main() {\n        if NSClassFromString(\"XCTestCase\") != nil {    // 3\n            TestApp.main()\n        } else {\n            MyRealApp.main()\n        }\n    }\n}\n```\n\nThere are three key points that make this work:\n\n<ol>\n\t<li>We need a dummy `App` struct to use instead of the real app.  This simple stand-in circumvents all your usual app startup machinery.  Instead of all the normal bootstrapping, we'll just get a window with the text \"I'm running tests!\".</li>\n<li>Remove the `@main` from your `App` implementation and add it here to `TestDriver`.  Swift uses `@main` to figure out how to start your app.  The `App` protocol provides a default implementation that, according to the docs, 'manages the launch process in a platform-appropriate way'.  But by inserting our own wrapper layer here around, we can control _which_ `main()` is called.</li>\n<li>That brings us to the final point, use the good old `NSClassFromString` to decide if the testing bundle has been injected into our process.  `XCTestCase` is only available during testing, so this is a reliable way to decide if unit testing is underway.  Based on that, we can call the `main` method of either our real app or our testing stand-in.  It turns out that the default implementation of `main` knows to use its parent struct to bootstrap the SwiftUI app.</li>\n</ol>\n\nNow when I run unit tests, my coverage is at 0.8%!  That's more like it.  In order to boost my test coverage, I now have to actually test code.  And the code coverage metric really starts to mean something.\n",
				"date_published": "2023-04-24T13:56:15-04:00",
				"url": "https://www.bugsandbunnies.org/2023/04/24/better-app-launching.html",
				"tags": ["Swift"]
			},
			{
				"id": "http://jaylyerly.micro.blog/2023/04/18/life-uh-finds.html",
				
				"content_html": "<p><em>Life, uh… finds a way\n</em>\n<p><a href=\"https://9to5mac.com/2023/04/18/kindle-unlimited-porn/\">Kindle Unlimited porn discovered by parents; Apple &lsquo;concerned&rsquo;</a></p></p>\n",
				"content_text": "<em>Life, uh… finds a way\n</em>\n<p><a href=\"https://9to5mac.com/2023/04/18/kindle-unlimited-porn/\">Kindle Unlimited porn discovered by parents; Apple 'concerned'</a></p>\n",
				"date_published": "2023-04-18T09:46:16-04:00",
				"url": "https://www.bugsandbunnies.org/2023/04/18/life-uh-finds.html"
			},
			{
				"id": "http://jaylyerly.micro.blog/2023/04/14/hey-no-cameras.html",
				
				"content_html": "<p>Hey!  No cameras! #BunnyButtFriday #RabbitsOfMastodon</p>\n\n<p><img src=\"uploads/2023/361c425a6b.jpg\" width=\"450\" height=\"600\" alt=\"\"></p>\n",
				"content_text": "Hey!  No cameras! #BunnyButtFriday #RabbitsOfMastodon \n\n<img src=\"uploads/2023/361c425a6b.jpg\" width=\"450\" height=\"600\" alt=\"\">\n",
				"date_published": "2023-04-14T10:41:31-04:00",
				"url": "https://www.bugsandbunnies.org/2023/04/14/hey-no-cameras.html"
			},
			{
				"id": "http://jaylyerly.micro.blog/2023/04/12/unit-testing-with.html",
				"title": "Unit testing with UIDocumentPickerViewController -- An Un-Googlable Bug",
				"content_html": "<p>TLDR &ndash; If your unit tests crash with <code>DocumentManager service tried to send a message to a deallocated host proxy</code>, make sure you&rsquo;re dismissing any presented instance of UIDocumentPickerViewController.</p>\n\n<p>In our <a href=\"https://callistoapp.com\">Callisto</a> Xcode project, we&rsquo;ve got a lot of unit tests.  Like over a thousand.  We&rsquo;re at the point where if tests have a 0.1% chance of failing, then it happens <em>every time</em>.  Our tests need to be really rock solid, or there&rsquo;s no way we&rsquo;ll get a clean run which is the only way CI will let a build through.</p>\n\n<p>Some time ago, we started noticing the occasional test failure with an uncaught exception:</p>\n\n<blockquote>\nDocumentManager service tried to send a message to a deallocated host proxy\n</blockquote>\n\n<p>It would crop up when running test both locally and in CI.  With so many tests, we get the weird edge case now and then, but they&rsquo;re not worth the time to track down.  We ignored it.  With the recent update to Xcode 14.3 and macOS 13.3, the DocManager exception went from occasional annoyance to &lsquo;omg, this happens every time I unit test on iOS&rsquo;.  So now we have to fix it.</p>\n\n<p>But what&rsquo;s a DocManager?  IDK &ndash; there&rsquo;s nothing with that name in our code and nothing in the docs about an Apple framework called DocManager.  Looking through the traceback, it&rsquo;s pretty obvious that it&rsquo;s some kind of internal Apple thing.  Surprisingly, a Google search for this error returns <em>absolutely no results</em>.  That&rsquo;s never a good sign.</p>\n\n<p>But what&rsquo;s a DocManager do?  Callisto is UIDocument based, so maybe DocManager manages documents?  A bunch of the unit tests open instances of a UIDocument and aren&rsquo;t 100% about cleaning those up, so maybe some housekeeping will help.  Cue the plumbing montage.  We added a some bookkeeping to make sure that any open UIDocuments were closed at the end of each test, so now we&rsquo;re sure there are no dangling UIDocuments.  No impact &ndash; still the DocManager throws the exception.</p>\n\n<p>This particular problem is a huge pain to track down.  Somewhere in the tests, things get into a bad state.  Later, while another test is running, some background thread discovers the bad state and throws an exception.  The cause of the crash and the actual crashing are quite loosely coupled, making it hard to pin down the culprit.  It also means that the offending tests will run just fine by itself, but only cause a crash when a large number of tests run, giving the background issue time to percolate to the surface.</p>\n\n<p>After a couple hours of testing the tests and narrowing down which ones fail, it started to look like UIDocumentPickerViewController might be involved.  We&rsquo;ve got some ViewControllers that open a docPicker and get feedback via the docPicker&rsquo;s delegate methods.  To test those, we programmatically tap a button to cause the dockPicker to be presented, get a handle to that docPicker and call the delegate with the docPicker and some fake results.  This works great for testing!  Except for that pesky exception that gets thrown now and then.</p>\n\n<p>If we take a closer look at the exception, we&rsquo;ll see there&rsquo;s a little more info attached in the userInfo dict, specifically a file and line number, DOCRemoteViewControlller.m line 42.  Not that we have access to the source, but the name of the file, &ldquo;Remote View Controller&rdquo;, does offer a hint of its purpose.  Those docPicker view controllers offer our app an escape hatch out of the sandbox and into the rest of the file system on the device.  In my limited understanding, the docPickers interface with a separate process that manages file system access, so they actually represent some state from another (<strong>remote</strong>) long lived process.  In the end, these dangling, un-dismissed docPickers were the root of the problem.  Make sure all your UIDocumentPickerViewControllers are dismissed properly and the problem goes away.</p>\n\n<p>Whew!</p>\n",
				"content_text": "TLDR -- If your unit tests crash with `DocumentManager service tried to send a message to a deallocated host proxy`, make sure you're dismissing any presented instance of UIDocumentPickerViewController.\n\nIn our [Callisto](https://callistoapp.com) Xcode project, we've got a lot of unit tests.  Like over a thousand.  We're at the point where if tests have a 0.1% chance of failing, then it happens _every time_.  Our tests need to be really rock solid, or there's no way we'll get a clean run which is the only way CI will let a build through.\n\nSome time ago, we started noticing the occasional test failure with an uncaught exception:\n\n<blockquote>\nDocumentManager service tried to send a message to a deallocated host proxy\n</blockquote>\n\nIt would crop up when running test both locally and in CI.  With so many tests, we get the weird edge case now and then, but they're not worth the time to track down.  We ignored it.  With the recent update to Xcode 14.3 and macOS 13.3, the DocManager exception went from occasional annoyance to 'omg, this happens every time I unit test on iOS'.  So now we have to fix it.\n\nBut what's a DocManager?  IDK -- there's nothing with that name in our code and nothing in the docs about an Apple framework called DocManager.  Looking through the traceback, it's pretty obvious that it's some kind of internal Apple thing.  Surprisingly, a Google search for this error returns _absolutely no results_.  That's never a good sign.\n\nBut what's a DocManager do?  Callisto is UIDocument based, so maybe DocManager manages documents?  A bunch of the unit tests open instances of a UIDocument and aren't 100% about cleaning those up, so maybe some housekeeping will help.  Cue the plumbing montage.  We added a some bookkeeping to make sure that any open UIDocuments were closed at the end of each test, so now we're sure there are no dangling UIDocuments.  No impact -- still the DocManager throws the exception.\n\nThis particular problem is a huge pain to track down.  Somewhere in the tests, things get into a bad state.  Later, while another test is running, some background thread discovers the bad state and throws an exception.  The cause of the crash and the actual crashing are quite loosely coupled, making it hard to pin down the culprit.  It also means that the offending tests will run just fine by itself, but only cause a crash when a large number of tests run, giving the background issue time to percolate to the surface.\n\nAfter a couple hours of testing the tests and narrowing down which ones fail, it started to look like UIDocumentPickerViewController might be involved.  We've got some ViewControllers that open a docPicker and get feedback via the docPicker's delegate methods.  To test those, we programmatically tap a button to cause the dockPicker to be presented, get a handle to that docPicker and call the delegate with the docPicker and some fake results.  This works great for testing!  Except for that pesky exception that gets thrown now and then.\n\nIf we take a closer look at the exception, we'll see there's a little more info attached in the userInfo dict, specifically a file and line number, DOCRemoteViewControlller.m line 42.  Not that we have access to the source, but the name of the file, \"Remote View Controller\", does offer a hint of its purpose.  Those docPicker view controllers offer our app an escape hatch out of the sandbox and into the rest of the file system on the device.  In my limited understanding, the docPickers interface with a separate process that manages file system access, so they actually represent some state from another (**remote**) long lived process.  In the end, these dangling, un-dismissed docPickers were the root of the problem.  Make sure all your UIDocumentPickerViewControllers are dismissed properly and the problem goes away.\n\nWhew!\n",
				"date_published": "2023-04-12T11:04:29-04:00",
				"url": "https://www.bugsandbunnies.org/2023/04/12/unit-testing-with.html",
				"tags": ["Swift"]
			},
			{
				"id": "http://jaylyerly.micro.blog/2023/04/11/excuse-me-waiter.html",
				
				"content_html": "<p>Excuse me waiter, there&rsquo;s a bit of hay in my water.  #RabbitsOfMastodon</p>\n\n<p><img src=\"uploads/2023/e416cb60d2.jpg\" width=\"483\" height=\"600\" alt=\"A big ruby eyed white rabbit looks at the camera, expressing her impatience because there is a large hay cake in her water bowl.  \"></p>\n",
				"content_text": "Excuse me waiter, there's a bit of hay in my water.  #RabbitsOfMastodon \n\n<img src=\"uploads/2023/e416cb60d2.jpg\" width=\"483\" height=\"600\" alt=\"A big ruby eyed white rabbit looks at the camera, expressing her impatience because there is a large hay cake in her water bowl.  \">\n",
				"date_published": "2023-04-11T14:33:56-04:00",
				"url": "https://www.bugsandbunnies.org/2023/04/11/excuse-me-waiter.html"
			},
			{
				"id": "http://jaylyerly.micro.blog/2023/01/07/philosophical-dragon.html",
				
				"content_html": "<p>Philosophical Dragon</p>\n\n<p><img src=\"uploads/2023/55d522ccb0.jpg\" width=\"450\" height=\"600\" alt=\"\"></p>\n",
				"content_text": "Philosophical Dragon \n\n<img src=\"uploads/2023/55d522ccb0.jpg\" width=\"450\" height=\"600\" alt=\"\">\n",
				"date_published": "2023-01-07T15:10:31-04:00",
				"url": "https://www.bugsandbunnies.org/2023/01/07/philosophical-dragon.html"
			},
			{
				"id": "http://jaylyerly.micro.blog/2023/01/04/marsedit.html",
				"title": "MarsEdit 5",
				"content_html": "<p>Tried to pay for an upgrade to MarsEdit 5 this morning, but it wouldn&rsquo;t let me.  The web store said I had purchased MarsEdit 4 too recently, and it gave me a free upgraded to version 5.  Nice!</p>\n",
				"content_text": "Tried to pay for an upgrade to MarsEdit 5 this morning, but it wouldn't let me.  The web store said I had purchased MarsEdit 4 too recently, and it gave me a free upgraded to version 5.  Nice! \n",
				"date_published": "2023-01-04T11:12:52-04:00",
				"url": "https://www.bugsandbunnies.org/2023/01/04/marsedit.html"
			},
			{
				"id": "http://jaylyerly.micro.blog/2022/11/27/greg-garcias-sprung.html",
				
				"content_html": "<p>Greg Garcia’s Sprung on Amazon Prime Video is quite good. He’s the creator behind My Name is Earl and Raising Hope. If you liked those, Sprung will be right up your alley. Some familiar faces too. So good.</p>\n",
				"content_text": "Greg Garcia’s Sprung on Amazon Prime Video is quite good. He’s the creator behind My Name is Earl and Raising Hope. If you liked those, Sprung will be right up your alley. Some familiar faces too. So good. \n",
				"date_published": "2022-11-27T15:32:18-04:00",
				"url": "https://www.bugsandbunnies.org/2022/11/27/greg-garcias-sprung.html"
			},
			{
				"id": "http://jaylyerly.micro.blog/2022/09/11/the-thinking-brick.html",
				
				"content_html": "<p>The Thinking Brick</p>\n\n<p><img src=\"uploads/2022/6c1f906e1c.jpg\" width=\"600\" height=\"450\" alt=\"\" /></p>\n",
				"content_text": "The Thinking Brick\n\n<img src=\"uploads/2022/6c1f906e1c.jpg\" width=\"600\" height=\"450\" alt=\"\" />\n",
				"date_published": "2022-09-11T20:00:12-04:00",
				"url": "https://www.bugsandbunnies.org/2022/09/11/the-thinking-brick.html"
			},
			{
				"id": "http://jaylyerly.micro.blog/2022/09/09/a-new-watch.html",
				"title": "A New Watch!",
				"content_html": "<p>I took the plunge and ordered a new <a href=\"https://www.apple.com/apple-watch-ultra/\">Ultra</a> Apple Watch sight unseen.  I&rsquo;m very excited for a new wrist computer, especially with a big orange button!  Seems weird though that there&rsquo;s no <em>titanium</em> watch band to dress it up.  I guess Apple is going full tilt on the outdoor adventure lifestyle to start.  The fancy matching titanium band will probably show up in the spring.</p>\n\n<p>(I desperately want to make an <a href=\"https://en.wikipedia.org/wiki/Ultraman\">Ultraman</a> joke, but <em>obviously</em> I&rsquo;m no Ultraman.)</p>\n",
				"content_text": "I took the plunge and ordered a new [Ultra](https://www.apple.com/apple-watch-ultra/) Apple Watch sight unseen.  I'm very excited for a new wrist computer, especially with a big orange button!  Seems weird though that there's no _titanium_ watch band to dress it up.  I guess Apple is going full tilt on the outdoor adventure lifestyle to start.  The fancy matching titanium band will probably show up in the spring.\n\n(I desperately want to make an [Ultraman](https://en.wikipedia.org/wiki/Ultraman) joke, but _obviously_ I'm no Ultraman.)\n",
				"date_published": "2022-09-09T09:05:01-04:00",
				"url": "https://www.bugsandbunnies.org/2022/09/09/a-new-watch.html"
			},
			{
				"id": "http://jaylyerly.micro.blog/2022/08/19/holy-shift-koenigseggs.html",
				"title": "Holy Shift! Koenigsegg’s New Transmission Is a 6-Speed Manual *and* a 9-Speed Automatic",
				"content_html": "<p>I always wondered if someone would build a clutch-by-wire system like this where there&rsquo;s a gear shift and a clutch, but not physically linked to the drivetrain.  This Koenigsegg gearbox sounds like just the thing.  The problem now is that we&rsquo;re all switching to gear-less electric motors, so will this come to electrics too?  Make &lsquo;em feel like a Miata?  I guess Dodge is going to try with the <a href=\"https://electrek.co/2022/08/17/dodge-shows-banshee-electric-charger-concept-an-ev-with-exhaust/\">eRupt</a>.</p>\n\n<p><a href=\"https://www.motortrend.com/reviews/koenigsegg-light-speed-transmission-manual-automatic-how-it-works-explained\">Holy Shift! Koenigsegg’s New Transmission Is a 6-Speed Manual *and* a 9-Speed Automatic</a>:</p>\n\n<blockquote>\"We still are in the process of developing it, but it's already crazy good. When we are done with it, I don't think anyone will be able to tell it apart from a traditional manual. That's the objective. It should feel like a mix between a Mazda Miata and a Ferrari gated shifter. The best of the two worlds.\"</blockquote>\n",
				"content_text": "I always wondered if someone would build a clutch-by-wire system like this where there's a gear shift and a clutch, but not physically linked to the drivetrain.  This Koenigsegg gearbox sounds like just the thing.  The problem now is that we're all switching to gear-less electric motors, so will this come to electrics too?  Make 'em feel like a Miata?  I guess Dodge is going to try with the [eRupt](https://electrek.co/2022/08/17/dodge-shows-banshee-electric-charger-concept-an-ev-with-exhaust/).\n\n<p><a href=\"https://www.motortrend.com/reviews/koenigsegg-light-speed-transmission-manual-automatic-how-it-works-explained\">Holy Shift! Koenigsegg’s New Transmission Is a 6-Speed Manual *and* a 9-Speed Automatic</a>:</p>\n\n<blockquote>\"We still are in the process of developing it, but it's already crazy good. When we are done with it, I don't think anyone will be able to tell it apart from a traditional manual. That's the objective. It should feel like a mix between a Mazda Miata and a Ferrari gated shifter. The best of the two worlds.\"</blockquote>\n",
				"date_published": "2022-08-19T14:30:07-04:00",
				"url": "https://www.bugsandbunnies.org/2022/08/19/holy-shift-koenigseggs.html"
			},
			{
				"id": "http://jaylyerly.micro.blog/2022/08/19/on-the-occasion.html",
				"title": "Serendipity ",
				"content_html": "<p>On the occasion of a blind squirrel finding a nut.</p>\n\n<p>Wordle 426 2/6\n<br>\n⬜🟩⬜🟨⬜\n<br>\n🟩🟩🟩🟩🟩</p>\n",
				"content_text": "On the occasion of a blind squirrel finding a nut. \n\nWordle 426 2/6\n<br>\n⬜🟩⬜🟨⬜\n<br>\n🟩🟩🟩🟩🟩\n",
				"date_published": "2022-08-19T09:29:46-04:00",
				"url": "https://www.bugsandbunnies.org/2022/08/19/on-the-occasion.html"
			},
			{
				"id": "http://jaylyerly.micro.blog/2022/08/12/sponge-worthy.html",
				"title": "Sponge worthy?",
				"content_html": "<p>My favorite new unix too is definitely <code>sponge</code>.  It&rsquo;s from the <a href=\"https://joeyh.name/code/moreutils/\">moreutils</a> suite, but the easiest way to get it on your Mac is a quick <code>brew install sponge</code>.</p>\n\n<p>You know how <code>sed</code> can edit a file in place?  Dope, right?  <code>sponge</code> makes it easy to do that with <em>all</em> the regular unix tools.  If I want to fix a DOS text file by removing the carriage return, I always try doing</p>\n\n<pre><code>cat my_file.txt | tr -d &quot;\\r&quot; &gt; my_file.txt\n</code></pre>\n\n<p>But that doesn&rsquo;t work because it starts writing to the file before it&rsquo;s all read and a lot of times, the file ends up empty.  <code>sponge</code> to the rescue!</p>\n\n<pre><code>cat my_file.txt | tr -d &quot;\\r&quot; | sponge my_file.txt\n</code></pre>\n\n<p><code>sponge</code> will read everything from standard in and then write it out to the given file, so this works like you want it to, even for big files.</p>\n\n<p>Also great with <a href=\"https://stedolan.github.io/jq/\"><code>jq</code></a> for prettifying JSON files in place too.</p>\n",
				"content_text": "My favorite new unix too is definitely `sponge`.  It's from the [moreutils](https://joeyh.name/code/moreutils/) suite, but the easiest way to get it on your Mac is a quick `brew install sponge`.\n\nYou know how `sed` can edit a file in place?  Dope, right?  `sponge` makes it easy to do that with _all_ the regular unix tools.  If I want to fix a DOS text file by removing the carriage return, I always try doing\n\n```\ncat my_file.txt | tr -d \"\\r\" > my_file.txt\n```\n\nBut that doesn't work because it starts writing to the file before it's all read and a lot of times, the file ends up empty.  `sponge` to the rescue!\n\n\n```\ncat my_file.txt | tr -d \"\\r\" | sponge my_file.txt\n```\n\n`sponge` will read everything from standard in and then write it out to the given file, so this works like you want it to, even for big files.\n\nAlso great with [`jq`](https://stedolan.github.io/jq/) for prettifying JSON files in place too.\n",
				"date_published": "2022-08-12T11:27:03-04:00",
				"url": "https://www.bugsandbunnies.org/2022/08/12/sponge-worthy.html"
			},
			{
				"id": "http://jaylyerly.micro.blog/2022/08/10/three-habits.html",
				"title": "Three Habits",
				"content_html": "<p><em>The three hardest habits to break are heroin, carbs and a steady paycheck.\n</em></p>\n\n<p><em>&ndash; Nassim Nicholas Taleb (paraphrased)</em></p>\n",
				"content_text": "<em>The three hardest habits to break are heroin, carbs and a steady paycheck. \n</em>\n\n<em>-- Nassim Nicholas Taleb (paraphrased)</em>\n",
				"date_published": "2022-08-10T15:03:08-04:00",
				"url": "https://www.bugsandbunnies.org/2022/08/10/three-habits.html"
			},
			{
				"id": "http://jaylyerly.micro.blog/2022/08/08/illinois-tech-spinout.html",
				"title": "Illinois Tech ‘spinout’ startup Influit Energ | EurekAlert!",
				"content_html": "<p>A research group out of Chicago has developed &ldquo;liquid batteries&rdquo;.  I have no idea how the chemistry of this works, but it sounds like you could refuel an electric car a lot like you&rsquo;d gas up an ICE car, and in a similar amount of time.  And about a billion other applications.</p>\n\n<p><a href=\"https://www.eurekalert.org/news-releases/961148\">Illinois Tech ‘spinout’ startup Influit Energ | EurekAlert!</a>:</p>\n\n<blockquote>The unique high-energy density liquid format of the NEF flow batteries allows use of the same fluids in different devices, meaning fluid, charged at the recharging station from renewable energy sources or a grid, can be used to rapidly refuel vehicles, or for stationary storage and other large portable applications,” Timofeeva says. “Discharged fluid can be returned to a recharge/refuel station for recharging or be charged inside the device by plugging into the power source.</blockquote>\n",
				"content_text": "A research group out of Chicago has developed \"liquid batteries\".  I have no idea how the chemistry of this works, but it sounds like you could refuel an electric car a lot like you'd gas up an ICE car, and in a similar amount of time.  And about a billion other applications.\n\n<p><a href=\"https://www.eurekalert.org/news-releases/961148\">Illinois Tech ‘spinout’ startup Influit Energ | EurekAlert!</a>:</p>\n\n<blockquote>The unique high-energy density liquid format of the NEF flow batteries allows use of the same fluids in different devices, meaning fluid, charged at the recharging station from renewable energy sources or a grid, can be used to rapidly refuel vehicles, or for stationary storage and other large portable applications,” Timofeeva says. “Discharged fluid can be returned to a recharge/refuel station for recharging or be charged inside the device by plugging into the power source.</blockquote>\n",
				"date_published": "2022-08-08T09:34:15-04:00",
				"url": "https://www.bugsandbunnies.org/2022/08/08/illinois-tech-spinout.html"
			},
			{
				"id": "http://jaylyerly.micro.blog/2022/08/04/muppet-songs-ernie.html",
				"title": "Muppet Songs: Ernie - Rubber Duckie - YouTube",
				"content_html": "<p>Today&rsquo;s earworm&hellip;</p>\n\n<p><a href=\"https://www.youtube.com/watch?v=hBvtD6xs77g\">Muppet Songs: Ernie - Rubber Duckie - YouTube</a>:</p>\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/hBvtD6xs77g\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n",
				"content_text": "Today's earworm...\n\n<p><a href=\"https://www.youtube.com/watch?v=hBvtD6xs77g\">Muppet Songs: Ernie - Rubber Duckie - YouTube</a>:</p>\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/hBvtD6xs77g\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n",
				"date_published": "2022-08-04T11:27:46-04:00",
				"url": "https://www.bugsandbunnies.org/2022/08/04/muppet-songs-ernie.html",
				"tags": ["Earworm"]
			},
			{
				"id": "http://jaylyerly.micro.blog/2022/08/03/daring-fireball-whats.html",
				"title": "Daring Fireball: 'What's the Deal With Water Bottles?'",
				"content_html": "<p>From the New Yorker via DF, a delightful survey of comics and their water bottles.  As a kid with cable, I watched a lot of standup, so I found this extremely interesting.  And the presentation is <em>molto bene</em> &ndash; the animated magazine version of the web.</p>\n\n<p><a href=\"https://daringfireball.net/linked/2022/08/01/water-bottles-standup\">Daring Fireball: 'What's the Deal With Water Bottles?'</a>:</p>\n",
				"content_text": "From the New Yorker via DF, a delightful survey of comics and their water bottles.  As a kid with cable, I watched a lot of standup, so I found this extremely interesting.  And the presentation is _molto bene_ -- the animated magazine version of the web.\n\n<p><a href=\"https://daringfireball.net/linked/2022/08/01/water-bottles-standup\">Daring Fireball: 'What's the Deal With Water Bottles?'</a>:</p>\n",
				"date_published": "2022-08-03T09:48:52-04:00",
				"url": "https://www.bugsandbunnies.org/2022/08/03/daring-fireball-whats.html"
			},
			{
				"id": "http://jaylyerly.micro.blog/2022/08/01/tricorders.html",
				"title": "Tricorders",
				"content_html": "<p>When I was a kid, I expected my tricorder would look like this</p>\n\n<p><img style=\"display:block; margin-left:auto; margin-right:auto;\" src=\"https://www.bugsandbunnies.org/uploads/2022/36af399d1b.jpg\" alt=\"Yokogawa AQ1200\" title=\"yokogawa-AQ1200.jpg\" border=\"0\" width=\"599\" height=\"486\" /></p>\n\n<p>But it turned out like this</p>\n\n<p><img style=\"display:block; margin-left:auto; margin-right:auto;\" src=\"https://www.bugsandbunnies.org/uploads/2022/8ceebb569f.jpg\" alt=\"158438 phones review iphone 13 pro review a lesson in refinement image5 ws2nobt8ak\" title=\"158438-phones-review-iphone-13-pro-review-a-lesson-in-refinement-image5-ws2nobt8ak.jpg\" border=\"0\" width=\"600\" height=\"400\" /></p>\n\n<p>Which still seems weird.</p>\n\n<p>Via <a href=\"https://wilwheaton.tumblr.com/post/691173806602141696/vizreef-yokogawa-aq1200-multi-field\">WIL WHEATON dot TUMBLR dot COM - vizreef: Yokogawa // AQ1200 Multi Field...</a>:</p>\n",
				"content_text": "When I was a kid, I expected my tricorder would look like this\n\n<img style=\"display:block; margin-left:auto; margin-right:auto;\" src=\"https://www.bugsandbunnies.org/uploads/2022/36af399d1b.jpg\" alt=\"Yokogawa AQ1200\" title=\"yokogawa-AQ1200.jpg\" border=\"0\" width=\"599\" height=\"486\" />\n\nBut it turned out like this\n\n<img style=\"display:block; margin-left:auto; margin-right:auto;\" src=\"https://www.bugsandbunnies.org/uploads/2022/8ceebb569f.jpg\" alt=\"158438 phones review iphone 13 pro review a lesson in refinement image5 ws2nobt8ak\" title=\"158438-phones-review-iphone-13-pro-review-a-lesson-in-refinement-image5-ws2nobt8ak.jpg\" border=\"0\" width=\"600\" height=\"400\" />\n\nWhich still seems weird.\n\n<p>Via <a href=\"https://wilwheaton.tumblr.com/post/691173806602141696/vizreef-yokogawa-aq1200-multi-field\">WIL WHEATON dot TUMBLR dot COM - vizreef: Yokogawa // AQ1200 Multi Field...</a>:</p>\n",
				"date_published": "2022-08-01T16:07:19-04:00",
				"url": "https://www.bugsandbunnies.org/2022/08/01/tricorders.html"
			},
			{
				"id": "http://jaylyerly.micro.blog/2021/08/04/twos-company-get.html",
				
				"content_html": "<p>Two’s company. Get lost nerd.</p>\n\n<p><img src=\"uploads/2021/35869d6666.jpg\" width=\"600\" height=\"450\" alt=\"\" /></p>\n",
				"content_text": "Two’s company. Get lost nerd. \n\n<img src=\"uploads/2021/35869d6666.jpg\" width=\"600\" height=\"450\" alt=\"\" />\n",
				"date_published": "2021-08-04T21:42:00-04:00",
				"url": "https://www.bugsandbunnies.org/2021/08/04/twos-company-get.html",
				"tags": ["Rabbit"]
			},
			{
				"id": "http://jaylyerly.micro.blog/2021/08/04/the-mysterious-error.html",
				"title": "The MYSTERIOUS Error.",
				"content_html": "<p>Callisto is a Catalyst app, mostly running iOS style code on a Mac.  But there are some things that Catalyst apps can&rsquo;t do &ndash; like run a python server as another process.  But Mac apps can!</p>\n\n<p>There are a lot of instructions around the Internet about how to use AppKit code within your Catalyst app to do those Mac things that Catalyst doesn&rsquo;t cover yet.  <a href=\"https://www.highcaffeinecontent.com/blog/20190607-Beyond-the-Checkbox-with-Catalyst-and-AppKit\">This article</a> from Steve Troughton-Smith was our guide.</p>\n\n<p>We also want to do auto-updates like a regular Mac app.  We&rsquo;re distributing outside the Mac App Store for Reasons, so we&rsquo;re in charge of our own updates.  Yep, dear reader, that means <a href=\"https://sparkle-project.org\">Sparkle</a>, which should be fine, right?  So we get the Sparkle framework and link it in to our AppKit bundle which is a plugin for our main app.  Compile, run and 💥.  This error is staring at us from the console.</p>\n\n<pre><code>code signature in (&lt;full path redacted&gt;/Sparkle.framework/Versions/A/Sparkle) not valid for use \nin process using Library Validation: not allowing mapping of development code into production process\n</code></pre>\n\n<p>What does <em>that</em> mean?  After some furious googling, we&rsquo;re left empty handed and confused.  The worst kind of error is that special, <em>new</em> error that no one else has ever seen.  Bollocks.</p>\n\n<p>After some futile futzing around in the dark, I give up and burn a &lsquo;code level&rsquo; support ticket with Apple.  I send a fairly detailed outline of the problem and the next morning I get back a nice response asking for more details.  In particular, how are the app and the framework code signed?  (You can check that with <code>codesign -vvvd &lt;.app or .framework&gt;</code>.)</p>\n\n<p>And immediately, I see it.</p>\n\n<p>App Signature:</p>\n\n<p><code>Authority=Developer ID Application: Oak City Labs, LLC (XXXXXXXXX)</code></p>\n\n<p>Framework Signature:</p>\n\n<p><code>Authority=Apple Development: Continuous Integration (YYYYYYYYY)</code></p>\n\n<p>The app is signed with a <em>production</em> identity while the framework is signed with a <em>development</em> identity.  That&rsquo;s what that weird error meant about <code>not allowing mapping of development code into production process</code>.  The <code>codesign</code> docs point out how frameworks and apps need to both be signed with the same Team ID (which I checked), but don&rsquo;t mention this distinction between production / development signing identities.</p>\n\n<p>I update Xcode so that the AppKit bundle was being signed with the same production identity and all is well!  We are fully Sparkle enabled!  Curiously, the AppKit bundle has always been signed with the development identity before, yet it loaded fine at runtime.  That must be one of those fine distinctions between a bundle and a framework that I don&rsquo;t quite understand.</p>\n\n<p>But now we celebrate!  🎉🎉🎉</p>\n",
				"content_text": "Callisto is a Catalyst app, mostly running iOS style code on a Mac.  But there are some things that Catalyst apps can't do -- like run a python server as another process.  But Mac apps can! \n\nThere are a lot of instructions around the Internet about how to use AppKit code within your Catalyst app to do those Mac things that Catalyst doesn't cover yet.  [This article](https://www.highcaffeinecontent.com/blog/20190607-Beyond-the-Checkbox-with-Catalyst-and-AppKit) from Steve Troughton-Smith was our guide.\n\nWe also want to do auto-updates like a regular Mac app.  We're distributing outside the Mac App Store for Reasons, so we're in charge of our own updates.  Yep, dear reader, that means [Sparkle](https://sparkle-project.org), which should be fine, right?  So we get the Sparkle framework and link it in to our AppKit bundle which is a plugin for our main app.  Compile, run and 💥.  This error is staring at us from the console.\n\n```\ncode signature in (<full path redacted>/Sparkle.framework/Versions/A/Sparkle) not valid for use \nin process using Library Validation: not allowing mapping of development code into production process\n```\n\nWhat does _that_ mean?  After some furious googling, we're left empty handed and confused.  The worst kind of error is that special, _new_ error that no one else has ever seen.  Bollocks.  \n\nAfter some futile futzing around in the dark, I give up and burn a 'code level' support ticket with Apple.  I send a fairly detailed outline of the problem and the next morning I get back a nice response asking for more details.  In particular, how are the app and the framework code signed?  (You can check that with `codesign -vvvd <.app or .framework>`.)\n\nAnd immediately, I see it.  \n\nApp Signature:\n\n`Authority=Developer ID Application: Oak City Labs, LLC (XXXXXXXXX)`\n\nFramework Signature:\n\n`Authority=Apple Development: Continuous Integration (YYYYYYYYY)`\n\nThe app is signed with a _production_ identity while the framework is signed with a _development_ identity.  That's what that weird error meant about `not allowing mapping of development code into production process`.  The `codesign` docs point out how frameworks and apps need to both be signed with the same Team ID (which I checked), but don't mention this distinction between production / development signing identities.\n\nI update Xcode so that the AppKit bundle was being signed with the same production identity and all is well!  We are fully Sparkle enabled!  Curiously, the AppKit bundle has always been signed with the development identity before, yet it loaded fine at runtime.  That must be one of those fine distinctions between a bundle and a framework that I don't quite understand.\n\nBut now we celebrate!  🎉🎉🎉\n\n\n",
				"date_published": "2021-08-04T09:24:31-04:00",
				"url": "https://www.bugsandbunnies.org/2021/08/04/the-mysterious-error.html"
			},
			{
				"id": "http://jaylyerly.micro.blog/2021/08/04/throw-some-results.html",
				"title": "Throw some Results ",
				"content_html": "<p>Errors, we&rsquo;ve all got &lsquo;em.  What do we do with &lsquo;em?</p>\n\n<p>Swift has a couple of different error handling patterns.  There&rsquo;s <code>try</code> and <code>catch</code> which I always think of as kind of the nuclear option.  Something went wrong, the code blows up with a <code>throw</code> and our hero, the intrepid programmer, has to deal with it right here, right now.  And then there&rsquo;s <code>Result</code>, an elegant weapon for a more civilized age.  Call a method and get back a <code>Result</code>, then deal with it as you like &ndash; check for the value, handle the error or maybe even ignore it altogether.  Depending on your situation, one of these is likely to suit better than the other.</p>\n\n<p>But sometimes the situation changes.  Maybe you wrote some code that should obviously <code>throw</code>(or calls some library code that <code>throws</code>), but it would really make a lot more sense to return a <code>Result</code>.  As it turns out, it&rsquo;s really easy to convert between <code>try</code>/<code>catch</code> and a <code>Result</code> type.</p>\n\n<p>Imagine you have some code that can <code>throw</code>.  Maybe even it always throws, because it is a <code>badIdea()</code>.  But you need to have a <code>Result</code> instance instead.  The <code>Result</code> type has an initializer that handles this perfectly.  You hand it a closure that returns the <code>Success</code> type for the <code>Result</code> and any error thrown by the closure is used for the <code>Failure</code> case.  Basically, they&rsquo;ve wrapped up all the boilerplate in this initializer, and you get a very concise way to convert <code>try</code> into a <code>Result</code>.</p>\n\n<pre><code class=\"language-swift\">enum HorrendousError: Error {\n    case veryBad\n}\n\nfunc badIdea() throws -&gt; String {\n    throw HorrendousError.veryBad\n}\n\nlet result = Result&lt;String, Error&gt; { try badIdea() }\n\n</code></pre>\n\n<p>The full signature of that initializer is <code>Result.init(catching: () -&gt; Success)</code>.  The single argument is a closure returns the <code>Success</code> type &ndash; here that&rsquo;s a <code>String</code>.  If the closure throws, then that gets wrapped up as the <code>.failure</code> case.</p>\n\n<p>How about doing the reverse?  You&rsquo;ve got a result type, but you&rsquo;d rather access the value in a <code>try</code> / <code>catch</code> sort of way.  The <code>Result</code> type itself has a accessor method for just such an occasion!</p>\n\n<pre><code class=\"language-swift\">let value = try someResult.get()\n</code></pre>\n\n<p>If the <code>Result</code> type is the <code>.success</code> case, it just returns the successful value.  If <code>someResult</code> is a <code>.failure</code> case, the <code>get()</code> method will <code>throw</code>.  This is especially useful if you want to access the result and ignore any errors:</p>\n\n<pre><code class=\"language-swift\">let optionalValue = try? someResult.get()\n</code></pre>\n\n<p>This is also handy in testing when you expect a <code>Result</code> type to be successful.  Use the <code>get()</code> method to access the value and let <code>XCTest</code>&rsquo;s support for tests that <code>throw</code> to handle the error cases.  This can make tests shorter and easier to read too.</p>\n\n<p>For me, discovering the interchangeable nature of <code>try</code>/<code>catch</code> and the <code>Result</code> type was a bit of an &lsquo;aha!&rsquo; moment.  You&rsquo;re not locked in to on type of error handling or another.  With these convenient converters, you can fluidly move from one type to another as needed.  And without a lot of boilerplate code for the conversions!</p>\n",
				"content_text": "Errors, we've all got 'em.  What do we do with 'em?\r\n\r\nSwift has a couple of different error handling patterns.  There's `try` and `catch` which I always think of as kind of the nuclear option.  Something went wrong, the code blows up with a `throw` and our hero, the intrepid programmer, has to deal with it right here, right now.  And then there's `Result`, an elegant weapon for a more civilized age.  Call a method and get back a `Result`, then deal with it as you like -- check for the value, handle the error or maybe even ignore it altogether.  Depending on your situation, one of these is likely to suit better than the other.\r\n\r\nBut sometimes the situation changes.  Maybe you wrote some code that should obviously `throw`(or calls some library code that `throws`), but it would really make a lot more sense to return a `Result`.  As it turns out, it's really easy to convert between `try`/`catch` and a `Result` type.\r\n\r\nImagine you have some code that can `throw`.  Maybe even it always throws, because it is a `badIdea()`.  But you need to have a `Result` instance instead.  The `Result` type has an initializer that handles this perfectly.  You hand it a closure that returns the `Success` type for the `Result` and any error thrown by the closure is used for the `Failure` case.  Basically, they've wrapped up all the boilerplate in this initializer, and you get a very concise way to convert `try` into a `Result`.\r\n\r\n\r\n```swift\r\nenum HorrendousError: Error {\r\n    case veryBad\r\n}\r\n\r\nfunc badIdea() throws -> String {\r\n    throw HorrendousError.veryBad\r\n}\r\n\r\nlet result = Result<String, Error> { try badIdea() }\r\n\r\n```\r\n\r\nThe full signature of that initializer is `Result.init(catching: () -> Success)`.  The single argument is a closure returns the `Success` type -- here that's a `String`.  If the closure throws, then that gets wrapped up as the `.failure` case. \r\n\r\nHow about doing the reverse?  You've got a result type, but you'd rather access the value in a `try` / `catch` sort of way.  The `Result` type itself has a accessor method for just such an occasion!\r\n\r\n```swift\r\nlet value = try someResult.get()\r\n```\r\n\r\nIf the `Result` type is the `.success` case, it just returns the successful value.  If `someResult` is a `.failure` case, the `get()` method will `throw`.  This is especially useful if you want to access the result and ignore any errors:\r\n\r\n```swift\r\nlet optionalValue = try? someResult.get()\r\n```\r\n\r\nThis is also handy in testing when you expect a `Result` type to be successful.  Use the `get()` method to access the value and let `XCTest`'s support for tests that `throw` to handle the error cases.  This can make tests shorter and easier to read too.\r\n\r\nFor me, discovering the interchangeable nature of `try`/`catch` and the `Result` type was a bit of an 'aha!' moment.  You're not locked in to on type of error handling or another.  With these convenient converters, you can fluidly move from one type to another as needed.  And without a lot of boilerplate code for the conversions!  \n",
				"date_published": "2021-08-04T09:24:01-04:00",
				"url": "https://www.bugsandbunnies.org/2021/08/04/throw-some-results.html"
			}
	]
}
